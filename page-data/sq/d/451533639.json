{"data":{"allMdx":{"nodes":[{"fields":{"slug":"/Engineering/Distributed Hash Table/","title":"Distributed Hash Table"},"frontmatter":{"draft":false},"rawBody":""},{"fields":{"slug":"/Engineering/Feature Flags/","title":"Feature Flags"},"frontmatter":{"draft":false},"rawBody":""},{"fields":{"slug":"/Engineering/Prometheus/","title":"Prometheus"},"frontmatter":{"draft":false},"rawBody":""},{"fields":{"slug":"/ML/Gradient Descend/","title":"Gradient Descend"},"frontmatter":{"draft":false},"rawBody":""},{"fields":{"slug":"/Coursera - Learning How to Learn/","title":"Week 1"},"frontmatter":{"draft":false},"rawBody":"# Week 1\n### 2 States of the mind: Focused and Diffused. \n- The focused mode is when we are focusing on a problem, intensely using pre-built thought pathways in our minds. \n- The diffused mode is when we are not focusing (doing sport, sleeping, cooking, ...). This disengagement of the mind from a particular subject allows higher level abstraction to be built\n\n### The are 2 (main) state of memory: working and Long term memories\n- Working memory is used for short term tasks. We have up to 4 slots or `chunks` of information we can store in our working memory. These slots are temporary so we will forget them pretty quickly.\n- Long term memory is used for keeping information for a long period of time. It is not easy to add new memories there.\n\nTo build knowledge is to create `stable` pathways in our minds. Moving thought processes and memories from short term to long term srtorage. \n\n\n### Learning habits\nTo learn something properly, we need to:\n1. work hard on it. Making the effort to experience new pathways. Being passive is way less productive than active in the learning process (for example watchiung a video <<<< doing the implementation yourself). \n2. Then relax, sleep, meditate, cook, do something else. This freeze the attention and allows your brain to assimilate the information. During this step the brain will digesty the information and build new neurological pathways. Sleeping is very important to build this pathways.\n3. Repeat 1. and 2. ! This process helps to migrate the memory from working to long term storage.\n\n### The Pomodoro technique\nIf you are having a hard time starting a new study, because it is hard, especially if you procrastinate, the pomodoro techniques helps you: \n1. Use a timer, give yourself 25 min (you can adapt) of study the material\n2. Take a break. This gives you a (small) reward after the effort. Which motivates you further and reduces the pain / angst again this study\n\n## Take away\n- Efficient learning involves going back and forth between Focused and Diffused modes.\n- Metaphors provide powerful techniques for learning \n- Learning something difficult takes time. Acknowledge it ! \n- Practice makes knowledge permanent\n- You have to add rest in between focus events (use pomodoro if need be)\n- Using `Spaced repetition` is very good to migrate information from Working to Long term memory. The Anki app is one tool do follow Spaced repetition.\n- Sleeping is very important to learn:\n\t- Clean brains \n\t- Is healthy \n\t- Clears unused pathways and strengthen the others ! \n\nStudying something just before going to bed is also powerful. Your brain will work harder on it over night.\n\n__________________\n__________________\n\n\n# Week 2\n\n## Chunking\nA chunk is a compact packages of information that your mind can easily access.  \nChunking is a logical package of pieces of information to make them easier to work with this concept.\n\nThe human can sustain 4 chunks in his working memory.\nA chunk is a network of neurones that are used to firing together.  \n\n### How to form a chunk ? \n1. You need to be in focus mode. no TV or anything else. Chunking relies on building new patterns using already existing one. This does not happen well if we are not focused.\n2. You need to understand the concept you are looking to chunk. This can be done by alternating btw Focused and Diffused mode. \n\t**But understanding how a problem is solved does not mean you create a chunk**. You need to **do it**, and make sure you can use this knowledge.\n3. It is important to build **context**. which is about surrounding information connecting them to the chunk. For example doing problems related to the original chunk. This will create new neural connections to the chunk you are building which makes it easier to come back to in different situations.\n\nLearning is a 2 step process.. Chunking is a `bottom-up` way to build a chunk (one by one, to learn a specific thing). Practice will increase the number of chunks related to each other. Using the big-picture (diffused mode) you will be able to connect chunks together. This builds the **Context** that relate chunks into one another.\n![[Pasted image 20220124212910.png|600]]\n\n![[Pasted image 20220124212611.png|500]]\n\n\n## Illusions of competence in Learning\n### Importance of Recall\nIt is better to recall the information of a text just read rather than re-reading the material. The learning is faster and much deeper.\n**The retrieval process itself is useful for remembering.**\n\n### Illusion of competence\nReading the solution of a solution, and thinking `I understand what they did here`. This is not knowing and you will not improve.\n\nIn the same way, reading google solutions will keep the illusion of competence.\n\nre-reading and highlirting too much text promotes ILLUSION OF Competence. \n\n--> **Testing yourself promotes long term learning via stabilising activations patterns in a large brain area.**\n--> Do Mini testing !!!!!!!!\n--> You can train to recall your information in different rooms in order to dissociate the knowledge from where you learned it.\n\n### Value of making mistakes\nMistakes are useful during mini testing. These mistakes help correct your thinking.\n\n\n\n## Seeing the bigger Picture\n### Library of chunks\n\nHaving many chunks helps to have a library of knowledge. You need to practice with growing chunks in order to remember and srtill be able to recall / use them.\n\n### Two ways to solve problem:\n1. Sequential thinking, using the focused mode\n2. or Holistic (global) approahc. Using intuition / Diffuse modes. A solutuon the diffuse mode provide should be verified in a focused mode.\n\n\n## Interleaving\n- **Overlearning** is when you work too much on the same material within the **same session** . It is still usefull to master something, but be careful when to use it.\n- Doing also the same thing you already know in further sessions is not good and give an illusion of competence again. \n- We need to do a **Deliberate practice** which is about balancing your study, studying what you find difficult.\n- Einstellung: an idea you already have in mind prevent a better idea or solution of being found.  You need to make sure that your original intuition is not false.\n- **Interleaving**: Once you have learned a new material / chunk and are not very familiar with it, interleaving is about balancing practicing with problems of different types around this chunk.\n\nInterleave is very important. it helps to build this creative pattern that you can rely on in new problems.\n\n\n\n## Summary\n- Chunks are pieces of information that are bound together through use and through meaning.\n- Chunk is a single easy item to access that uses one slot in the working memory. \n- Chunks are build with Focused attention, understanding and practice\n- Simple Recall (remembering the key points without looking at the page) is a powerful way to build chunks. \n\t- Bonus to recalling memory in different locations.\n- `Transfer` is the fact that you can relate chunks over different domains. They will help you learn new chunks\n- Interleaving learning by practicing your choice of concepts and techniques. This helps at becoming flexible with which chunks to use\n- Test yourself !!! this is a good way of avoiding the illusions of competence.\n- Mistakes are good.\n- Avoid practicing at easy stuff.\n- Einstellung is when an idea you already have in mind prevents a better idea / solutions from being found.\n- L:aw of Serendipity: just learn one thing, and you will see that the next one will be a little bit simpler to learn.\n"},{"fields":{"slug":"/","title":"Brain Dam"},"frontmatter":{"draft":false},"rawBody":"# Brain Dam\n\nThis website contains notes following (or trying to) the [Zettelkasten principles](https://zettelkasten.de/introduction/).\n\n\n"},{"fields":{"slug":"/Start here/","title":"Start Here"},"frontmatter":{"draft":false},"rawBody":"Hi there! I'm a note in your vault.\n\nAt the same time, I'm also just a Markdown file sitting on your hard disk. It's all in plain text, so you don't need to worry about losing me in case [[Obsidian]] disappears one day.\n\n## Quick Start\n\nIf you're in a hurry, here's some quick places to dive in:\n\n- The [[Command palette]] contains most of the commands you need to work with Obsidian. Just press `Ctrl/Cmd-P` and start typing.\n- How to [[Create notes|create new notes]].\n- How to create [[Internal link|internal links]]\n- How to use Markdown to [[Format your notes]]\n- How to [[embed files]], or embed other notes\n- [[Keyboard shortcuts]]\n- How to [[Working with multiple notes|open multiple files side by side]]\n- Obsidian can be extended with [[List of plugins|plugins]]. Several are available by default, and can be enabled or disabled according to your needs.\n\n\nIf you want a more thorough introduction, including a bit about our philosophy, check out [[Obsidian]].\n\nAnd if you'd like a gentle introduction, or just want to get started but don't know how, head over to [[Basic note taking]].\n\nIf you are a [Catalyst supporter](https://obsidian.md/pricing), and want to turn on Insider Builds, see [[Insider builds]].\n\n## Workflows\n\nObsidian is a tool that can be used in many ways, from a simple list of notes to a very powerful knowledge management system. We suggest you start at your own pace, and build it into the tool you need.\n\nHere are a few ways to get started:\n\nIf you want to just start taking notes, check out [[Basic note taking]]\n\nIf you already have a collection of notes in markdown format, just choose them for your Vault. Choose \"Vault\" in the lower left and select the directory your notes are in.\n\nIf you have notes from Roam Research, Notion, or other systems, [[Import data|here's how to import them]].\n\nIf you'd like to know more about Obsidian, you can [[Obsidian|read about our story]].\n\nBy the way, you can feel free to edit these help docs, but when you open it again, they will be overwritten. So, don't put anything in them you want to keep.\n\n## I have questions.\n\nThen you should join our [community!](https://obsidian.md/community). We have active Discord and Forums, and the community is generally quite helpful.\n"},{"fields":{"slug":"/Azure/Azure pipeline/","title":"Azure Pipeline"},"frontmatter":{"draft":false},"rawBody":"### Example azure pipeline with conda / mamba: \n[Fermitools-conda/master/azure-pipelines.yml](https://github.com/fermi-lat/Fermitools-conda/blob/master/azure-pipelines.yml) \n(or a fixed point in history)\n[Fermitools-conda/@commit/azure-pipelines.yml](https://github.com/fermi-lat/Fermitools-conda/blob/8c9676019c917be688ace1a1b8ddc5b24471bf92/azure-pipelines.yml)\n\n\n### In pipeline.yml using `bash` vs `script` commands\nSee documentation [consider-bash-or-pwsh](https://docs.microsoft.com/en-us/azure/devops/pipelines/scripts/cross-platform-scripting?view=azure-devops&tabs=yaml#consider-bash-or-pwsh)"},{"fields":{"slug":"/Engineering/API Design/","title":"API Design"},"frontmatter":{"draft":false},"rawBody":"Pagination\nCRUD Operations."},{"fields":{"slug":"/Engineering/Caching/","title":"Cache for read"},"frontmatter":{"draft":false},"rawBody":"\n# Cache for read\n\n# Update Cache on Writes\n## Write through Cache\nHave the cache and DB in sync when there is a write. Downside is that it takes time.\n\n## Write back Cache\nThe server updates only the cache upon a write, then goes back to client. This makes the cache out of sync with the Database. The system will asynchronously update the DB. At every intervals, or when the cache is filled up (when you need to `evict` the cache).  \n\nDownside: if something happens to the cache, before there is a write to DB, then you may loose data.\n\n\n# What happens if we have many servers that do caches ?\nThe first client writes a comment, it is cached to Server 1 and saved in DB. Client 2 reads the comment from another server 2, this server 2 caches the comments.  \nThe first clients updates the comment. How do we make sure the client 2 gets the new comments that is still cached in server 2 as the old text ? Caches can become `stale` if they have not been updated properly.\n\nFor example, a solution would be to have a single cache (like [[Redis]]) out of the servers, that would be the single source of truth. \n\nFor some features, we may not care about `staleness`, for example view count on youtube videos.\n\n```mermaid \ngraph LR\nClient_1\nClient_2\nServer_1\nServer_2\nRedis\nDatabase\n\nClient_1 --> Server_1\nClient_2 --> Server_2\nServer_1 --> Redis\nServer_2 --> Redis\n\nRedis --- Database\n```\n\n# When to use cache\nIf you deal with data that is immutable, caching is easy and great. If the data is mutable, that is a big work. \n- using Cache is you use immutable data. \n- If you have a single thing that read / write data then we can use cache\n- If you don't care about consistency / staleness of data, you can use caching\n- If you are able to design your system to get rid of stale data (in a distributed manner if your system uses it) then you can use cache\n\n# Cache eviction\nYou cannot store infinite data, or you have stale data, you need to get rid of data in Caches (`eviction`).   \nUsing schedules / policies:\n- LRU: Get rid of the Least Recently Used data in cache. \n- Least frequently used: Remove the least frequently used\n- LIFO or FIFO\n- Randomly\n- Every day"},{"fields":{"slug":"/Engineering/Client-Server Model/","title":"Client-Server Model"},"frontmatter":{"draft":false},"rawBody":"```mermaid\ngraph TD\nClient\nServer\nDNS\n\nClient -- Step 1 --> DNS\nClient --  Step 3 <br> HTTP request --> Server\nDNS -- \"Step 2 - IP@\" --> Client\nServer -- Step 4 <br> HTTP response --> Client\n```\n\nServer are waiting for requests from clients. Server licenses to requests on Ports. There are 16000 ports to listen to.\n- HTTP uses port 80\n- HTTPS uses port 443\n- "},{"fields":{"slug":"/Engineering/Configuration/","title":"Configuration"},"frontmatter":{"draft":false},"rawBody":"Configuration is a set of parameters / constants that your application uses. These parameters are configurable in a file in order to be edited easily.  \nYou can use it for [[Feature Flags]].\n\nThere are 2 types of configurations:\n- `Static` : You have to change the configuration file, then deploy the application. Pro's is that if the configuration change breaks the app, testing might pick it up. Static configuration is usually a bit safer but it takes longer to see the impact due to deployment.\n- `Dynamic` is done on the live system. It is more complex, because it is backed by a DB that the system is querying in order to pick up the update. This is beneficial as it allows the build of a UI in order to change the system live. Pro's you can make changes and see their changes fast. Con's you do not have the same testing framework.\n\nUsually we use dynamic configuration and build added guarantees to prevent too many issues when changes configurations, for example:\n- not everyone can do the configuration change, ie access control\n- add a review process\n- apply the update every hour for example\n- deploy only to a few users\n\n\n"},{"fields":{"slug":"/Engineering/Consistent hashing/","title":"Consistent hashing with bounded load"},"frontmatter":{"draft":false},"rawBody":"[High level explanation](https://www.toptal.com/big-data/consistent-hashing)\n[Tutorial with more details](https://docs.openstack.org/swift/latest/ring_background.html)\n\nGeneral Idea:\n1. Hash all the servers IDs (UUID, IP address, ...) and \"map\" them onto the unit circle.\n1. Hash the object you want to save (like username). Then \"map\" this hash onto the unit circle\n1. The location where to store an object is on the closest server on the unit circle in the anti-clockwise direction (for example). \n\nIf a node crashes, we need only to move this nodes data, ie `K/N` values, `K` being the number of keys and `N` the number of nodes / servers in the pool.  \nExample of 3 servers 5 keys to be mapped.\n![[Pasted image 20211110210818.png|700]]\n\nIt is better to have multiple hashes for a given servers (10x, 50x, 1000x ?) so that selecting the closest server for an object is more uniform. The number of keys per servers (10x, ...) depends on the server capacity. This is called the servers `weight`. \nExample of 3 servers with 10 keys per server.\n![[Pasted image 20211110211244.png|700]]\n\n# Consistent hashing with bounded load\n\n# Questions \n- How do you support duplication over multiple server to be resilient if a machine goes down ? Maybe we can assign a key to the 2 closest servers in the circle ? z\n\n\n# Other strategy\nSee [[Rendez-vous Hashing]]  \nSee [[Jump hashing]]"},{"fields":{"slug":"/Engineering/Etcd/","title":"Etcd"},"frontmatter":{"draft":false},"rawBody":"This is a [[Key-Value Stores|Key-Value Store]] that is [[Availability|highly available]] and Strongly Consistent store.  \nIt implements the RAFT consensus algorithm.\n\nWe can use this DB to implement leader election for our servers. You have multiple servers communicating with ETCD, and at any given point in time, you have a special Key-Value pair that represents who the leader is.\n\nThis is a tool like [[Zookeeper]]."},{"fields":{"slug":"/Engineering/Idempotent Operation/","title":"Idempotent Operation"},"frontmatter":{"draft":false},"rawBody":"An Operation that has the same ultimate outcome regardless of how many times it's performed. For example buying 5 times the same item should only charge the user once. Operations performed through a [[Publish-Subscribe Pattern|Pub/Sub]] messaging system typically have to be idempotent, since Pub/Sub systems tend to allow the same messages to be consumed multiple times..\n\n```mermaid \ngraph TD\nStart\nNS((\"New state\"))\n\nStart --\"apply method\"--> NS\nNS --\"apply method\"--> NS\n\n```"},{"fields":{"slug":"/Engineering/Jump hashing/","title":"Other strategy"},"frontmatter":{"draft":false},"rawBody":"# Other strategy\nSee [[Rendez-vous Hashing]]  \nSee [[Consistent hashing]]"},{"fields":{"slug":"/Engineering/Key-Value Stores/","title":"Tools"},"frontmatter":{"draft":false},"rawBody":"**Useful for caching or dynamic configuration.**  \nWhen you want to use a database that does not enforce relational format (in SQL).\n\nBecause we are accessing value directly thoruigh keys, you can access values very fast. Usually you have lower latency and increrased throughput.\n\n\n| Key | Value |\n|-----|-------|\n| foo | 9001           |\n| bar | SystemsExpert  |\n| baz | 1, two, 3      |\n\n# Tools\n- [[Redis]] (in memory storage)\n- Dynamo DB\n- ZooKeeper\n- Etcd\n"},{"fields":{"slug":"/Engineering/Latency and Throughput/","title":"Latency"},"frontmatter":{"draft":false},"rawBody":"Measure of performance of a system\n\n# Latency\nhow long it takes for data to go through a system. \n\t- network request  from client to server and back to client.\n\t- Time taken to read data:   \n\t\treading 1MB from memory: $2~\\micro\\text{seconds}$   \n\t\treading 1MB from SSD: $1000 ~\\micro \\text{ seconds}$  \n\t\treading 1MB from 1GB/s network : $10,000 ~\\micro \\text{ seconds}$  \n\t\treading 1MB from HDD : $20,000 ~\\micro \\text{ seconds}$  \n\t\tsend a packet from California to Netherlands and back : $150,000 ~\\micro \\text{ seconds}$\n\t\t\n```mermaid\ngraph LR\nClient\nServer\n\nClient --> Server\nServer --> Client\n```\n\n\n# Throughput\nHow much data can be send through the system over a given amount of time.\n\nHow to optimize for throughput: you can party for it to increase the number of servers.\n\n```mermaid\ngraph TD\nClient_1\nClient_2\nClient_3\n...\nClient_N\n\nServer\n\n\nClient_1 --> Server\nClient_2 --> Server\nClient_3 --> Server\n... --> Server\nClient_N --> Server\n```\n\n\nLatency and Throughput are not correlated."},{"fields":{"slug":"/Engineering/Leader Election/","title":"How to implement Leader election for your service ?"},"frontmatter":{"draft":false},"rawBody":"If you have a group of servers in charge of doing the same \"thing\" (like charging a user). `Leader Election` has the servers in question elect one of them as a `leader`, and that leader server is responsible to do this single action.  \nThe other servers (the `followers`) stays online, and if the `leader` goes down, a new leader is elected out of the `followers`.\n\nThis subject is hard because it is difficult to share the state of the knowledge of who the leader is. The act of getting `concensus` is hard.\n\n# How to implement Leader election for your service ? \nWe can use [[Etcd]]  (maybe Zookeeper) DB to implement leader election for our servers. You have multiple servers communicating with ETCD, and at any given point in time, you have a special Key-Value pair that represents who the leader is.  \nFor example the leader key could be `leader`. \n# Tools\n- [[Zookeeper]]\n- [[Etcd]]\n\n# Consensus Algorithm\n- Paxos \n- Raft\n"},{"fields":{"slug":"/Engineering/Load Balancer/","title":"How does the load balancer work ?"},"frontmatter":{"draft":false},"rawBody":"This is a server that can distributes loads between a bunch of servers.\n```mermaid \ngraph LR\nClient_1\nClient_...[...]\nClient_N\n\nLD((\"Load Balancer<br>(Reverse Proxy)\"))\nServer_1\nServer_...[...]\nServer_S\n\nClient_1 --> LD\nClient_... --> LD\nClient_N --> LD\n\nLD --> Server_1\nLD --> Server_...\nLD --> Server_S\n```\n\n# How does the load balancer work ?\nThere are Software vs hardware load balancer. The software has more customization and scaling capability. Here we will talk about software load balancer.\n\n## How does a LB has a new server to route to ?\nAdding a new server will register itself to the LB\n\n## How do we select the server to send to ? \n- Pure random redirection.\n- Round Robin approach: goes through server from top to bottom and come back to first one.\n- Weighted Round Robin: Still go through the first to the last server, but redirects more traffic or less depending on the weight. This would be useful if you have some more powerful servers \n- Using health checks, the LB can identify which server is struggling.\n- IP based LB: using a hash of the IP address of the client gets routed to a given server. This is useful when you have caching, because all the request of this client are going to the same server, this improves cache hits.\n- Cache based strategy: all the request related to a given path in the URL go to a given server. Useful if we want to deploy a big change to a given path, this change will only impact the servers that support this part of the path. All other services on the platform are unaffected in case of failure of deployment.\n\n\n## Using multiple LB\nIt makes sens to have multiple LB.\n\nFor example one LB using IP @, followed by LB following round robin\n\n```mermaid \ngraph LR\nClient_1\nClient_...[...]\nClient_N\n\nLD_IP((\"Load Balancer<br>(IP @ routing)\"))\n\nLD_RR1((\"Load Balancer<br>(Round Robin)\"))\nLD_RR2((\"Load Balancer<br>(Round Robin)\"))\n\nServer_1\nServer_2\nServer_3\nServer_4\n\nClient_1 --> LD_IP\nClient_... --> LD_IP\nClient_N --> LD_IP\n\nLD_IP --> LD_RR1\nLD_IP --> LD_RR1\nLD_IP --> LD_RR1\nLD_IP --> LD_RR1\n\nLD_IP --> LD_RR2\nLD_IP --> LD_RR2\nLD_IP --> LD_RR2\nLD_IP --> LD_RR2\n\n\n\nLD_RR1 --> Server_1\nLD_RR1 --> Server_1\nLD_RR1 --> Server_2\nLD_RR1 --> Server_2\nLD_RR2 --> Server_3\nLD_RR2 --> Server_3\nLD_RR2 --> Server_4\nLD_RR2 --> Server_4\n```\n\n## Redundant LB\nYou can have multiple load balancer to help in case of failure of a LB server. These servers communicate btw each other.\n\n# Tools\n**Nginx**"},{"fields":{"slug":"/Engineering/Logging and Monitoring/","title":"Logging"},"frontmatter":{"draft":false},"rawBody":"# Logging\n## Tools\n- Google Stack Driver\n\n\n# Monitoring\nUse a time series DB (Like influx DB, Graphite, Prometheus). And you have your server sending data to these DB.  \nYou can use tools like Graphana to connect to these DB and build graphs.\n\nYou can use monitoring to build alerts."},{"fields":{"slug":"/Engineering/MapReduce/","title":"Important points"},"frontmatter":{"draft":false},"rawBody":"MapReduce is based on the assumptions that most data processing tasks can be split up into a `map` and a `reduce` functions.\n\n```mermaid \ngraph LR\n\nAA(('AA'))\nAB(('AB'))\nAAC(('AAC'))\nBBB(('BBB'))\n\nKV1((\"k/v<br>pairs\"))\nKV2((\"k/v<br>pairs\"))\nKV3((\"k/v<br>pairs\"))\nKV4((\"k/v<br>pairs\"))\n\nN1((\"A\"))\nN2((\"B\"))\nN3((\"C\"))\n\nOutput((\"Output\"))\n\nAA --Map--> KV1\nAB --Map--> KV2\nAAC --Map--> KV3\nBBB --Map--> KV4\n\nKV1 --Shuffle--> N1\nKV2 --Shuffle--> N1\nKV2 --Shuffle--> N2\nKV3 --Shuffle--> N1\nKV3 --Shuffle--> N3\nKV4 --Shuffle--> N2\n\nN1 --Reduce--> Output\nN2 --Reduce--> Output\nN3 --Reduce--> Output\n\n```\n\nDo not forget, there is a `Shuffle` step between the Map and Reduce step !\n# Important points\n1. When dealing with MapReduce model, we assume we have a distributed file system. And the distributed FS has knowledge of where the data chunks reside and how to communicate with the machine that are going to apply the Map Operation (the `workers`).\n2. Because we have large dataset, we do not want to move the data, we move the Map operation (the map program) on the machines that contains the data.\n3. The Key-value pair after a Map operation is very important. The Reduce step relies on the Key to \"reduce\" / aggregate the data.\n4. MapReduce handles failures by re-doing a Map or Reduce operation. Hence our Map and Reduce functions are [[Idempotent Operation| idempotent]] !  (they do not change an external state)\n5. As an engineer dealing with a MapReduce job, what we care about is specifying Map and Reduce functions and their inputs / outputs.\n# Reference\n[MapReduce original white Paper](https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf)\n"},{"fields":{"slug":"/Engineering/Peer-To-Peer Networks/","title":"Tools"},"frontmatter":{"draft":false},"rawBody":"A collection of machines referred to as peers that divide a workload between themselves to presumably complete the workload faster than would otherwise be possible. Peer-to-Peer networks often used in file-distribution systems.\n\nYou want to send a big file to many many machines. \n\nYou split this file into very small chunks. Send these chunks to all machines. Then let all the machines talks to each other to request between themselves the remaining chunks to build back the original file.\n\nThis is way better than going one by leveraging parallelism.\n\nHow do we know which peer to send a given chunk of the file ? \n- Using a `tracker`: You can use a DB that knows which server got which chunk so far.\n- Using the `gossip protocol` / `epidemic protocol`: servers talk between themselves and figure out what they need from each other. This relies on a [[Distributed Hash Table]] (DHT)\n\n# Tools\n- Kraken from Uber."},{"fields":{"slug":"/Azure/Azure-ml/","title":"Documentation"},"frontmatter":{"draft":false},"rawBody":"# Documentation\n- [azureml-cheatsheets](https://azure.github.io/azureml-cheatsheets/)\n\n"},{"fields":{"slug":"/Engineering/Availability/","title":"SLA / SLO"},"frontmatter":{"draft":false},"rawBody":"What happens if the system fails. How fault tolerant is the system. The percentage of time where the system is satisfying its primary functions.\n# SLA / SLO\nSystem level agreement. System level objective. SLO are components of SLA. \n\n# Nines\nThe percentage of time where the system is running according to SLA is usually expressed in percentages with `9`, like 99% availability in a year, or 99.9%, 99.999%, ... Which are 2, 3, and 5 nines.\n\nSystems with `Highly Availability (HA)` are systems with more than 5 nines ~5 min of downtime. It is a official term \n# Redundancy\nRemoving Single Points of Failure is a way to improve availability. Redundancy is a way to duplicates (or more) your servers.   \n`Passive redundancy`: If a machine dies, the other machines already there will pick up the traffic.  \n`Active redundancy`: Only one or few of the machines doing work. If this one fail, the other machines are going to know and pick up the work. For example a Leader election, if the leader machine fails another machine will become leader."},{"fields":{"slug":"/Engineering/Polling and Streaming/","title":"Polling"},"frontmatter":{"draft":false},"rawBody":"# Polling\n```mermaid \ngraph LR\nC1(\"Client 1<br>Polling\")\n\nS1(\"Server 1\")\n\nC1 -- \"Request<br>every x seconds\" --> S1\nS1 --> C1\n```\nHave a client issue a request at every time interval.\n\n# Streaming\n```mermaid \ngraph LR\nC2(\"Client 1\")\n\nS2(\"Server 2<br>Streaming\")\n\nS2 -.\"Streaming<br>continuously\".-> C2\n```\nThe Server opens a [[Socket]] on the client.  \nStreaming is pushing data from your server to the client. Whereas polling requires the client to initialize the data exchange with a request.\nStreaming allows to have instantaneous information flow without having many request being done by clients."},{"fields":{"slug":"/Engineering/Proxies/","title":"Forward Proxy"},"frontmatter":{"draft":false},"rawBody":"There are `Forward` and `Reverse` proxies. By default a proxy is a forward proxy.\n\n# Forward Proxy\nA Forward Proxy (FP) is a server that is between a client (or a set of clients) and another server (or a set of servers). A FP is a server that acts on behalf of client(s). A FP is on the client's side. If a client wants to communicate with a server, when a client issues a request to the server, it goes to the proxy and the proxy forwards the request to the server. The server gets the request from the FP, when the server responses, it replies to the proxy and the proxy sends the replies to the client.\n\nSo to the server, the server does not know the IP of the client, but the proxy only.\n\n```mermaid \ngraph LR\nClient\nFP[\"(Foward) Proxy\"]\nServer\n\nClient --1--> FP\nFP --2--> Server\nServer --3--> FP\nFP --4--> Client\n```\n\n# Reverse Proxy\nA Reverse Proxy (RP) acts on behalf of a Server. If a client wants to send a request to a server, if the RP is set up properly, the RP will get the requests (while the clients thinks its going to the server). \n\n```mermaid \ngraph LR\nClient\nFP[\"(Reverse) Proxy\"]\nServer\n\nClient --1--> FP\nFP --2--> Server\nServer --3--> FP\nFP --4--> Client\n```\n\nThe key thing is that the client **THINKS** that it is communicating with the server. This is the difference with FP.\n\nRP are very useful. For example a RP can filter out request you want to ignore. it can log / collect metrics, cache html pages. \none of a best use case is to do [[Load Balancer | load balancing]]."},{"fields":{"slug":"/Engineering/Publish-Subscribe Pattern/","title":"Tools"},"frontmatter":{"draft":false},"rawBody":"```mermaid \ngraph TD\nP1((P1))\nP2((P2))\nP3((P3))\n\nT1[[T1]]\nT2[[T2]]\nT3[[T3]]\n\nS1((S1))\nS2((S2))\nS2((S3))\n\nP1 --Push--> T1\nP2 --Push--> T2\nP3 --Push--> T3\n\nS1 --Pull--> T1\nS2 --Pull--> T1\nS3 --Pull--> T3\n```\n\n4 entities:\n- `Publishers`: Servers publishing data (in the form of messages) into Topics.\n- `Subscribers`: Clients that subscribes to Topics.\n- `Topics`: Conceptual Channels of specific information.\n- `Message`: Represents the data that is relevant to the Subscriber to get/process.\n\n\nThis is closely related to [[Polling and Streaming|Streaming]].\n\nA Pub/Sub system is like a DB. You are guaranteed at **least once** delivery to a subscriber. This can lead to issues where the same message is send multiple times to the same server. This issue enforces the subscriber to have [[Idempotent Operation]].\n\n### Additional property:\n- Messages are send to Subscribers in the same order as they come in. This is the behavior of a queue.\n- It is possible to \"replay\" messages.\n\n### Why do we need multiple topics ? \nPub/Sub is like a Database, which means that we may want to have multiple \"tables\" (as in SQL). So for each type of data, we want to have multiple topics. These topics have different sets of subscribers.\n\n# Tools\n- Apache Kafka\n- Google Cloud pub/sub: Topics scales automatically, sharding at a topic level is handled automatically.\n"},{"fields":{"slug":"/Engineering/Rate Limiting/","title":"Tools"},"frontmatter":{"draft":false},"rawBody":"The act of limiting the number of request sent to or from a system. Rate Limiting is most often used to limit the number of incoming requests in order to prevent DoS attacks and can be enforced at the IP-address level, at the user-account level or at the region level. Rate limiting can also be implemented in tiers; for instance, a type of network request could be limited to 1 per second, 5 per 10 seconds and 10 per minute.\n\n# Tools\nYou can use [[Redis]] to implement rate limiting by recording the number of request in this DB."},{"fields":{"slug":"/Engineering/Redis/","title":"Redis"},"frontmatter":{"draft":false},"rawBody":"An In memory Key-value store. Does offer some persistent storage options but is typically used as a really fast, best-effort caching solution.   \nRedis is also often used to implement [[Rate Limiting]]"},{"fields":{"slug":"/Engineering/Relational Databases/","title":"ACID"},"frontmatter":{"draft":false},"rawBody":"Data stored in relational DB are stored as tables.  \n**Most Relation DB supports SQL, which is a major reason why you want to use a Relational DB. Do not under estimate the importance of the query you want to be able to run on the DB.**\n\n# ACID\nSQL DB must support ACID transactions:\n- Atomicity: this dictates that multiple sub-operation in a command will all succeed or all fail.\n- Consistency: There are no stale stale in a DB where a future transaction does not know that a past transaction has executed.\n- Isolation: \n- Durability: The effect of a transaction are permanent (for example data stored on disk) \n\n# Database Index\nYou can create an auxiliary data structure in your DB that is optimize for a given query. \n\nThere are many indexes possible:\n- Bitmap indexes\n- Reverse indexes\n- Dense indexes\n\n### Example table\nFor example if we want to build an index related to the query to find all the customer that have the maximum amount:\n\n| customer_name | processed_at | amount |\n|---------------|--------------|--------|\n| Clement       | 2019-12-01   | 10     |\n| Antoine       | 2019-11-16   | 200    | \n| Simon         | 2020-02-02   | 9001   |\n| Meghan        | 2020-02-01   | 700    |\n\nWe can sort this DB by the Amount column in the index, and then use this new index to quickly answer this query.\n\nHaving an auxiliary DB will increase the memory cost and the write cost since we have to write to the original DB and the index.\n\nExample query for creating an index:\n```SQL\nCREATE INDEX table_idx_name on existing_table(column);\n```"},{"fields":{"slug":"/Engineering/Rendez-vous Hashing/","title":"Other strategy"},"frontmatter":{"draft":false},"rawBody":"We use a ranking to assign a client to a server. If a server goes down in a cluster, the ranking of server for a given client should be the same if the the top server is still running.\n\n# Other strategy\nSee [[Consistent hashing]]  \nSee [[Jump hashing]]  "},{"fields":{"slug":"/Engineering/Replication and Sharding/","title":"Replication"},"frontmatter":{"draft":false},"rawBody":"A system's performance is often only as good as its database's; optimize the latter, and watch as the former improves in tandem!\n\n```mermaid \ngraph LR\n\nMD((\"Main DB\"))\nReplica((Replica))\n\nMD --Sync-->Replica\nMD -.Async.-> Replica\n```\n\n# Replication\nIf the DB goes down, the system is down as well because we cannot read from DB. To solve for this, we can have a duplicate / replica of the original DB, this is a standby of the real DB. The main DB ensures the replica is up to date.\n\nHow to we keep the replica up to date ?   \n## Synchronous update\nWhenever there is an update of the main DB, the replica is updated synchronously. If the replica update fails, the write command fails for the main DB fails as well.\n\nWe can also use replication to improve the latency of the DB.\n\n## Async update\nIt is possible to update the replica asynchronously. This is ok if we do not need the replicas to be super up to date (like Linkedin posts).\n\n# Sharding\nTo improve [[Latency and Throughput|throughput]] you can increase the replicas of a DB but this is limiting if the database if huge. So you may want to replicate specific subset of the data. Splitting the data across databases. Partitioning the data (this splitting) is known as **sharding**.\n\nHow do you know how to split the data and where to put it ?  \nFor example with tables, you can split up certain rows into different shards, for example by customer name.\n\n## Hotspots\nSome shards may get more traffic than other just by chance.  \nYou use hashing function to determine what shard a piece of data is gonna be written to and read from. [[Consistent hashing]] may be useful here, depending on the problem.\n\nThis logic of choosing how to do the sharding, you could implement it in the server that does the service itself. But in practice, this logic is implemented in a [[Proxies|Reverse Proxy]] that acts on behalf of the DB.\n\n\n# References\n[Azure sharding doc](https://docs.microsoft.com/en-us/azure/architecture/patterns/sharding)"},{"fields":{"slug":"/Engineering/Security and HTTPS/","title":"Encryption"},"frontmatter":{"draft":false},"rawBody":"HTTP can be hacked with a Man In The Middle attack.\n\n# Encryption\n## Symmetric encryption\nRelies on symmetric key, so a single key, to both encrypt and decrypt data.\nDownside, that one key has to be shared between the 2 machines. This s hard to make sure that no one else get the key.\nThis requires AES (advanced encryption standards)\n\n## Asymmetric\nRelies on 2 keys, public and private  keys. When you encrypt a message using the public key, you can only decrypt it using the private key.\n\n# HTTPS\n## TLS (handshake)\nTransport Layer Security, which is a secured layer. So HTTPS is using TLS to be secure.  \nThe 2 services establishes a secure connection during the `TLS handshake`. \n\n```mermaid\nsequence\n```\n\n## SSL (certificate)\nSecure Socket Layer."},{"fields":{"slug":"/Engineering/Socket/","title":"Socket"},"frontmatter":{"draft":false},"rawBody":"A Socket is a way to have a long lived connection between two machines.\n\nA socket is like a \"portal\" to another machine without having to make repeated connection request.\n\n[[Polling and Streaming|Streaming]] is done using sockets.\n"},{"fields":{"slug":"/Engineering/Specialized Storage Paradigms/","title":"Blob Store"},"frontmatter":{"draft":false},"rawBody":"# Blob Store\nA BLOB means Binary Large Object.  \nA BLOB in an arbitrary of storage data. For example a video, image, large text, binary file.  \nA BLOB store is a storage solution for BLOBs.  \nA BLOB does not fit in an SQL DB.   \n\nBLOB stores are optimize for storing and retrieving massive amount of storage.\n\nThey behave like Key-Value store. Usually you access the data piece through some key. BUT they are not the same ! Because BLOB store is not optimize in the same way as Key-value. \n\n## Tools\n- GCS (Google Cloud Storage)\n- S3 (AWS)\n- Azure Blob storage (Microsoft)\n\n\n# Time Series DB\nIs a DB that is specialized to store Time Series data.  \nLike monitoring, telemetry data, sensors (like IoT), stock prices.\n\n## Tools\n- Influx DB\n- [[Prometheus]]\n\n# Graph DB\nA Graph DB][=]\n## Tools\n- Neo4j\n\n\n# Spatial DB + QuadTree\n## Tools\n- "},{"fields":{"slug":"/Engineering/Storage concept/","title":"Storage Concept"},"frontmatter":{"draft":false},"rawBody":"A Database is a server that handles saving and reading data from.\n`Persistence`: Outage may destroy data depending if the DB is using `disk` vs `memory`.\nReading data from memory is much faster than from disk.\n\nDifferent parameters for choosing a database: \n- Persistence: Disk vs Memory \n- Enforces structure on data ?\n- Availability: single vs distributed\n- Consistency: ACID, eventual consistency\n- Read / Write speeds\n"},{"fields":{"slug":"/Engineering/Zookeeper/","title":"Zookeeper"},"frontmatter":{"draft":false},"rawBody":"Tool similar to [[Etcd]]."},{"fields":{"slug":"/ML/Bayesian AB testing/","title":"Tool"},"frontmatter":{"draft":false},"rawBody":"Why is it preferred over [[Frequentist AB testing]] ?\n- easier to interpret results. We don't have a p-value and a confidence interval, with Bayesian we can directly answer the question: what is the proba that B is better than experiment A.\n- Often fewer samples to each launch decision \n\t--> which means faster exp. \n\t--> which means faster improvements\n\t\n# Tool\n- Visual optimizer\n\n\n# Multi arm banding (MAB) vs AB\n![[Pasted image 20211220141202.png]]"},{"fields":{"slug":"/ML/Constrained optimization/","title":"Constrained Optimization"},"frontmatter":{"draft":false},"rawBody":"We wish to find the maximal or minimal value of $f(\\boldsymbol{x})$ for values of $\\boldsymbol{x}$ in some set $\\mathbb{S}$. This is known as constrained optimization. Points $\\boldsymbol{x}$ that lie within the set $\\mathbb{S}$ are called feasible points in constrained optimization terminology.\n\n- We can do gradient optimization with a small step size. Then project the obtained set of parameters back in the set $\\mathbb{S}$.  \n- We could do something similar with [[Line Search]] where we only considered feasible values $\\boldsymbol{x} \\in \\mathbb{S}$. \n- More sofisticated, the [[KKT]] approach."},{"fields":{"slug":"/ML/Coordinate descent/","title":"Coordinate Descent"},"frontmatter":{"draft":false},"rawBody":"[Coordinate descent](https://en.wikipedia.org/wiki/Coordinate_descent) is an optimization algorithm that successively minimizes along coordinate directions to find the minimum of a function. At each iteration, the algorithm determines a coordinate or coordinate block via a coordinate selection rule, then exactly or inexactly minimizes over the corresponding coordinate hyperplane while fixing all other coordinates or coordinate blocks. A [[Line Search]] along the coordinate direction can be performed at the current iterate to determine the appropriate step size. Coordinate descent is applicable in both differentiable and derivative-free contexts.\n\n### **Coordinate descent is applicable in both differentiable and derivative-free contexts.**\n\n\n![[Pasted image 20211213144445.png|500]]"},{"fields":{"slug":"/ML/Determinant/","title":"Determinant"},"frontmatter":{"draft":false},"rawBody":"$det(\\boldsymbol{A})$ maps a matrix to a scalar.  \n- The `determinant` is equal to the product of all eigenvalues of a matrix.\n- The absolute value of the determinant can be thought of as a measure of how much multiplication by the matrix expands or contracts space. \n- \n"},{"fields":{"slug":"/ML/Dirichlet distribution/","title":"Dirichlet Distribution"},"frontmatter":{"draft":false},"rawBody":"Exponential Family distribution over the Simplex (positive vectors that sums to 1).   \nA Dirichlet is parameterize by a K-1 vector named $\\alpha$. ($\\alpha$ does not sum to one, this is a parameter not a probability.)\n\nThe Dirichlet is a conjugate to the multinomial. \n\n- $E[\\theta_i | \\alpha] = \\frac{\\alpha_i}{\\sum\\alpha_i}$, ie the mean.\n- $\\sum \\alpha_i$ determine the peakiness of the Dirichlet, ie the scaling.\n\n##### What happens when $\\alpha < 1$ or equivalently $s < K$? \nInstead of having a \"peak\" in the dirichlet triangle, you get a \"bowl\" kind of, where the edges have higher values.\nThe samples categories get \"sparser\".\n\n\n##### Conjugacy\n$\\theta \\sim Dir(\\alpha)$ and  $Z_n \\sim Mult(\\theta)$, so what is conditional distribution $p(\\theta|Z_{1..N})$ ?\n\nLet $n(Z_{1..N})$ be counts of each atom (atom ?). then $\\theta|Z_{1..N} \\sim Dir(\\alpha + n(Z_{1..N}))$\n\n\n![[Pasted image 20211111134057.png]]"},{"fields":{"slug":"/ML/Eigendecomposition/","title":"Eigendecomposition"},"frontmatter":{"draft":false},"rawBody":"Decomposition of matrix into a set of `eigenvectors` and `eigenvalues`.\nAn `eigenvector` of square matrix $\\boldsymbol{A}$ is a non-zero vector $\\boldsymbol{v}$ such that multiplication by  $\\boldsymbol{A}$ alters only the scale of  $\\boldsymbol{v}$.\n$$\\boldsymbol{A} \\boldsymbol{v} = \\lambda \\boldsymbol{v}$$\n$\\lambda$ is the `eigenvalue` corresponding to this eigenvector.  \nConcatenating all eigenvectors per column into a matrix  $\\boldsymbol{V}$ and all eigenvalues into a vector  $\\boldsymbol{\\lambda}$.  \nThe `eigendecomposition` of  $\\boldsymbol{A}$   is then:\n$$ \\boldsymbol{A} =  \\boldsymbol{V} diag(\\boldsymbol{\\lambda})\\boldsymbol{V}^{-1}$$\nEvery real [[Symmetric matrix]] can be decomposed into an expression using only real-valued eigenvectors and eigenvalues: $\\boldsymbol{A} = \\boldsymbol{Q}\\boldsymbol{\\Lambda}\\boldsymbol{Q}^T$ where $\\boldsymbol{Q}$ is an orthogonal matrix composed of eigenvectors of $\\boldsymbol{A}$, and $\\boldsymbol{\\Lambda}$ is a diagonal matrix.\n\n##### A matrix is [[Singular matrix|singular]] iff any of the eigenvalues are zero.\n\nA matrix with all positive eigenvalues is called [[Positive Definite Matrix|positive definite]].  \nA matrix with all positive of zero-valued eigenvalues is called [[Positive Definite Matrix|positive semidefinite]].  \nA matrix with all negative eigenvalues is called `negative definite`.  \nA matrix with all negative of zero-valued eigenvalues is called `negative semidefinite`.\n"},{"fields":{"slug":"/ML/Frequentist AB testing/","title":"Frequentist A/B testing"},"frontmatter":{"draft":false},"rawBody":"Form an Hypothesis:\n- Replace a user experience with another\n- Dependent variable selection: eg the profit lift brought by the new change, increased click through rate, screen time, ...\n- Directionality of these dependent variables: identify the change of each dependent variables\n- Experiment participants\n\nTemplate: \n`\"If we replace X with Y for some distincts set of user, then [A, B, C] will go [up/down] and [invariants] won't change.\"`\n`[A, B, C]` are the dependent variables.\n\nsee [[Bayesian AB testing]]\n\n# Frequentist A/B testing\nControl group in which the experience is unchanged so that we can compare a treatment group. \n-> Determine if the treatment group should replace control group.\n\n\nRun for at least 2 weeks.\n### Results extrapolation\n- Through time\n- Through population\n\n### Impact of change:\n- novelty effect: user uses the new UI more because it's new, not because it's better\n- Change aversion: user don't use the new UI because it's different\n- Time intensive feedback: sometime, the chosen dependent variable we want to optimize takes too long to get. For example think graduation grades for master, if you change the first year course, it will take 4 years to get feedback. SUch a long period of time will surely have invariante variable change which is no good. -> we want feedback within a month\n\n# A/A testing\nTo measure that our dependent variables don't have crazy variance, and maybe to measure the `minimum detectable change` required to reject the null hypothesis, we can do A/A testing, which is running the same platform for 2 sets of users and measuring the p-value, etc of the hypothesis testing we will do in A/B testing. We expect to see that the null hypothesis is not rejected in this case.\n\n\n# Tools for A/B testing\n- Optimizely \n- Google optimize\n- Facebook plan out\n\n\n# Multi arm banding (MAB) vs AB\n![[Pasted image 20211220141202.png]]"},{"fields":{"slug":"/ML/GNN/","title":"Graph Neural Network"},"frontmatter":{"draft":false},"rawBody":"# Graph Neural Network\n\n# Good videos \n[Geometric Deep Learning: GNNs Beyond Permutation Equivariance](https://www.youtube.com/watch?v=aCUOAkOqNoU) Explaining why all NN can be considered GNNs.\n\n"},{"fields":{"slug":"/ML/Gradient/","title":"Gradient"},"frontmatter":{"draft":false},"rawBody":"The Gradient is the extension of derivative to the case where the derivative is with respect to a vector.  \nThe gradient of f is the vector containing all of the partial derivatives: \n$$\\nabla_x f(\\boldsymbol{x})$$\n\n- $f : \\mathbb{R} \\rightarrow \\mathbb{R}$: derivative\n- $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}$: Gradient $\\nabla_x f(\\boldsymbol{x}) \\in \\mathbb{R}^n$.\n- $f : \\mathbb{R}^m \\rightarrow \\mathbb{R}^n$: [[Jacobian]] $\\boldsymbol{J} \\in \\mathbb{R}^{n \\times m}$"},{"fields":{"slug":"/ML/Hessian/","title":"Hessian"},"frontmatter":{"draft":false},"rawBody":"The hessian is the collection of second derivative of the gradient. ie, the hessian is the [[Jacobian]] of the [[Gradient]].\n\n$$\\boldsymbol{H}(f)(\\boldsymbol{x})_{i, j} = \\frac{\\partial^2}{\\partial x_i \\partial x_j} f(\\boldsymbol{x})$$"},{"fields":{"slug":"/ML/Jacobian/","title":"Jacobian"},"frontmatter":{"draft":false},"rawBody":"The `Jacobian` is the extension of a gradient where the partial derivaties of a function whose input and output are both **vectors**.\n\nGiven a function $\\boldsymbol{f}: \\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{n}$, its Jacobian  $\\boldsymbol{J} \\in \\mathbb{R}^{n \\times m}$ is defined as $J_{i,j}  = \\frac{\\partial}{\\partial x_i} f(\\boldsymbol{x})_i$"},{"fields":{"slug":"/ML/KKT/","title":"KKT conditions"},"frontmatter":{"draft":false},"rawBody":"The **Karush–Kuhn–Tucker** (KKT) approach provides general solution to [[Constrained optimization]]. With the KKT approach, we introduce a new function called the `generalized Lagrangian`.\n\n# KKT conditions\nThese conditions are necessary, but not always sufficient, for a solution point to be optimal for the given generalized Lagrangian.\n- The gradient of the generalized Lagrangian is zero.\n- All contraints on both $\\boldsymbol{x}$ and the KKT multipliers are satisfied.\n- The inequality constraints exhibit \"complementary slackness\": $\\alpha \\odot \\boldsymbol{h}(\\boldsymbol{x}) = 0$"},{"fields":{"slug":"/ML/Kernel Trick/","title":"Kernel Trick"},"frontmatter":{"draft":false},"rawBody":"Well explained on page 11 of `Deep Learning` book by Ian Goodfellow, Yoshua Bengio, Aaron Courville. (in my paperpile or google drive)."},{"fields":{"slug":"/ML/Latent Dirichlet Allocation/","title":"Links"},"frontmatter":{"draft":false},"rawBody":"\nThis can be used for Topic Modeling.\n\nExtract topics from multiple documents. This is an unsupervised approach.\nLDA is a probabilistic model: \n- Treat data as obs that arise from a generative prob process that includes hidden variables\n\t- For Documents, the hidden variables reflect the thematic structure of the collection\n- Infer the hidden structure using posterior inference\n\t- What are the topics that describe this collection ? \n- Situate new data into the estimated model\n\t- How does this query or new document fit into the estimated topics.\n\nIn LDA, the intuition is that **Documents exhibit multiple topics**.\n\nThe underlying model of how a document is generated is based of: \n- Every topic **is** a distribution over a fixed vocab. \n- We have a distribution over the topics.\na document is a given distribution over the topics, then we sample topics, and then we sample one word for the sampled topic.\n\nGraphical model:\n![[Pasted image 20211111132355.png|700]]\n\nHow do we infer this model ? (the latent variables)\n\n##### Q: Why do we condition on $Z$ and $\\beta$ ? Why do we have a condition for W over ALL $\\beta_K$ and not just the beta for the given topic ?\n\n$p(W_{d,n} | Z_{d,n}, \\beta_K)$ because $Z_{d,n}$ is a topic index, using this topic index we can select this topic distribution from $\\beta_K$.\n\n##### Q: mixed membership model\nsee video in link below at ~1h5min\n\n# Links\n[Nice Lecture from David Blei](http://videolectures.net/mlss09uk_blei_tm/)\n"},{"fields":{"slug":"/ML/Line Search/","title":"Line Search"},"frontmatter":{"draft":false},"rawBody":"[Line search](https://en.wikipedia.org/wiki/Line_search) In optimization, the line search strategy is one of two basic iterative approaches to find a local minimum  $\\mathbf {x} ^{*}$ of an objective function $f:\\mathbb {R} ^{n}\\to \\mathbb {R}$ . The other approach is [[trust region]].\n\nThe line search approach first finds a descent direction along which the objective function {\\displaystyle f}f will be reduced and then computes a step size that determines how far $\\mathbf {x}$  should move along that direction. The descent direction can be computed by various methods, such as gradient descent or quasi-Newton method. The step size can be determined either exactly or inexactly."},{"fields":{"slug":"/ML/Matrix inverse/","title":"Matrix Inverse"},"frontmatter":{"draft":false},"rawBody":"A matrix has an inverse if it is square and all columns are linearly independent.  \nA square matrix that is not invertible is called `singular` or `degenerate`."},{"fields":{"slug":"/ML/Moore-Penrose Pseudoinverse/","title":"Moore-Penrose Pseudoinverse"},"frontmatter":{"draft":false},"rawBody":"Matrix inversion is not defined for matrices that are not square. \nTo get the pseudo inverse of a matrix $\\boldsymbol{A}$, we use the [[Singular Value Decomposition (SVD)|SVD]] of $\\boldsymbol{A}$. Then the pseudo inverse of $\\boldsymbol{A}$ is:\n\n$$\n\\boldsymbol{A}^+ = \\boldsymbol{V} \\boldsymbol{D}^+\\boldsymbol{U}^T\n$$\n\n"},{"fields":{"slug":"/ML/Multi-armed bandit (AB testing)/","title":"Exploitation vs exploration"},"frontmatter":{"draft":false},"rawBody":"Minimize the negative business impact of the B experiement while still experimenting at a reasonable pace.\n\n> note: it is not a good idea to just to regular AB testing with a smaller proportion of pop doing the B exp. Because in the need we need a significant amount of people doing the B exp in order to reject or not the hypothesis. so routing 99% to exp A and 1% to exp B is practically the same as doing 50/50. \n\n\nSo during the 14 day trials of this AB, we measure the performance at 7 days. and how do we choose to route customers more efficiently given this partial experiemnt so far ? \n\n# Exploitation vs exploration\n## Epsilon greed strategy\nHow much better is this epsilon greed vs regular AB testing. \n\n# Thomson sampling\nThe frequency a user should be allocated to an experiment should equal the probability of that experience being optimal.\n\n\n# Multi arm banding (MAB) vs AB\n![[Pasted image 20211220141202.png]]\n\n\n# Tool\n- Optimizely\n- Visual web optimizer\n- Vowpal Wabbit (contextual bandit)"},{"fields":{"slug":"/ML/Naive Bayes Classifier/","title":"Naive Bayes Classifier"},"frontmatter":{"draft":false},"rawBody":"Given a corpus of text and their label as training set, we want to build a classifier that can give us a class given a text.  \nMore formally, given a vector of multiple discrete values features $\\boldsymbol x \\in \\{1, ...K\\}^D$ and a target label $y$. \n\n$$\n\n\\begin{aligned}\n\np(y=c | \\boldsymbol x) & =  \\frac{p(y=c)p(\\boldsymbol x|y=c)}{p(\\boldsymbol x)} \\\\\n& = \\frac{p(y=c)\\prod_{i=1}^D p(x_i|y=c)}{p(\\boldsymbol x)} \\Leftarrow \\textit{ naive assumption of conditional independence}\n\\end{aligned}\n$$\n\nFor example, $\\boldsymbol x$ is a vector representing a document.\n1. If $x_i$ represents the absence or presence of $word_i$ in a text. In this case, $K = 2$ because $x_i \\in \\{0, 1\\}$\n2. If $x_i$ represents the frequency (count) of $word_i$ in a text, then $x_i$ can have any discrete value from 0 to infinity. So $x_i \\sim Cat(\\mu_i)$. A categorical distribution of the frequency to be 0, 1, 2, 125, ... So $\\mu_i$ is a vector of size $N$ which denotes the maximum frequency we have from the training set.   \n    If in the text test we have a greater frequency, the probability of having this frequency is 0 ???\n3. It is possible to handle other type of distribution for $x_i$ even different distributions for every features.\n\n### Directed Graphical Model\n![[Pasted image 20211215205658.png|200]] ^8d39ff\n\nWhere:\n- $\\boldsymbol \\pi$ is the prior of the categorical distribution of $Y$: $Y \\sim Cat(\\pi)$\n- $x_{ij}$ is the feature of the jth word for the ith document. $j \\in \\{1, ..., D\\}$ words (ie D is the vocab size) and $i \\in \\{1, ... N\\}$ documents. \n- $\\theta_{jc}$ is the parameter of the $x_{ij}$ feature variable. The document $i$  is associated with a label $y_i$ which has values in the possible class $C$. \n- The plates: there are $N$ documents, $D$ words across all N documents (vocab), there are $C$ possible outcome class values for $Y$. \n\n\n"},{"fields":{"slug":"/ML/Newton's method/","title":"Newton's Method"},"frontmatter":{"draft":false},"rawBody":"Gradient descend using second order derivative. The Taylor series is:\n$$\nf(\\boldsymbol{x}) \\approx f\\left(\\boldsymbol{x}^{(0)}\\right)+\\left(\\boldsymbol{x}-\\boldsymbol{x}^{(0)}\\right)^{\\top} \\nabla_{\\boldsymbol{x}} f\\left(\\boldsymbol{x}^{(0)}\\right)+\\frac{1}{2}\\left(\\boldsymbol{x}-\\boldsymbol{x}^{(0)}\\right)^{\\top} \\boldsymbol{H}(f)\\left(\\boldsymbol{x}^{(0)}\\right)\\left(\\boldsymbol{x}-\\boldsymbol{x}^{(0)}\\right)\n$$\n\nWe solve for the critical point of this function: \n$$\n\\boldsymbol{x}^{*}=\\boldsymbol{x}^{(0)}-\\boldsymbol{H}(f)\\left(\\boldsymbol{x}^{(0)}\\right)^{-1} \\nabla_{\\boldsymbol{x}} f\\left(\\boldsymbol{x}^{(0)}\\right)\n$$\nWhen $f$ is a positive definite quadratic function, Newton's method consists of applying the above equation to jump to the minimum, of the function directly. When the function is not quadratic but can be locally approximated as positive definite quadratic, Newton's method consists of applying the above equation multiple times."},{"fields":{"slug":"/ML/Norms/","title":"Norms"},"frontmatter":{"draft":false},"rawBody":"Norms are functions mapping vectors to non-negative values.\n\nA norm is any function $f$ that satisfies the following properties:\n$$\n\\begin{align}\n&\\bullet f(\\boldsymbol{x}) = 0 \\Rightarrow \\boldsymbol{x} = 0 \\\\\n&\\bullet f(\\boldsymbol{x} + \\boldsymbol{y}) \\le f(\\boldsymbol{x}) + f(\\boldsymbol{y}) \\\\\n&\\bullet \\forall \\alpha \\in \\mathbb{R}, f(\\alpha \\boldsymbol{x}) = |\\alpha|f(\\boldsymbol{x})\n\\end{align}\n$$\n"},{"fields":{"slug":"/ML/PCA/","title":"Maths"},"frontmatter":{"draft":false},"rawBody":"PCA is defined as an [orthogonal](https://en.wikipedia.org/wiki/Orthogonal_transformation \"Orthogonal transformation\") [linear transformation](https://en.wikipedia.org/wiki/Linear_transformation \"Linear transformation\") that transforms the data to a new [coordinate system](https://en.wikipedia.org/wiki/Coordinate_system \"Coordinate system\") such that the greatest variance by some scalar projection of the data comes to lie on the first coordinate (called the first principal component), the second greatest variance on the second coordinate, and so on.\n\n![[Pasted image 20211222145709.png | 300]]\n\n# Maths\nLet's have $X$ already mean centered (ie $X = X - \\overline{X}$). We want to find the new basis $W$ which vectors maximizes the variance along the axis. This matrix $W \\in \\mathcal{R}^{p \\times l}$ where $l \\le p$ since we can reduce the dimensionality.\nSo a sample $x_i$ is mapped to the new space as $t_i$ as: $t_{ik} = x_i \\times w_k$. \nAs the first vector $w_1$ explains most of the variance we have: \n$$\nw_i= \\underset{||w|| = 1}{argmax} ~ \\sum_{i=1}^n t_i ^ 2 = \\underset{||w|| = 1}{argmax} ~ \\sum_{i=1}^n (x_i \\times w) ^ 2\n$$\n\nUsing the matrix representation $X$: \n$$\nw_i = \\underset{||w|| = 1}{argmax} ~|| X \\times w ||^2  = \\underset{||w|| = 1}{argmax} ~\\{ w^T X^T X w \\}\n$$\nAs $w_1$ is a  unit vector, this is equivalent to:\n$$\nw_i = \\underset{w}{argmax}  ~\\{ \\frac{w^T X^T X w}{w^T w} \\}\n$$\nWe can identify here that this is problem is a Rayleigh quotient. The solution of this Equation with a Rayleigh quotient is the eigenvector with the largest eigenvalue ! \n\nTo find the $k^{th}$ vector of the $k^{th}$ largest variance, we remove the eigenvector from X:\n$$\n\\hat{X_k} = X - \\sum_{s=1}^{k-1} Xw_sw_s^T\n$$\nand then the associated eigenvalue is \n\n$$\nw_k = \\underset{||w|| =1}{argmax} ~|| \\hat{X_k} \\times w ||^2 = \\underset{w}{argmax}  ~\\{ \\frac{w^T \\hat{X_k}^T \\hat{X_k} w}{w^T w} \\}\n$$\nWhich is again a Rayleigh quotient and the solution is again an eigenvector. \n\nIn the end, the eigenvectors of $X$ are the basis that explains the variance the most."},{"fields":{"slug":"/ML/Parameter estimation/","title":"Parameter Estimation"},"frontmatter":{"draft":false},"rawBody":"We want to **estimate** (ie learn) the parameters $\\boldsymbol \\theta$  given a training set $\\mathcal{D} = \\{ (\\boldsymbol x_0, y_0), ..., (\\boldsymbol x_N, y_N) \\}$ of $N$ documents.\n\nWe can find\n- a **point estimate** of these parameters, ie a given value / vector / matrix for $\\boldsymbol \\theta$\n- or a distribution over these parameters space, ie a function $\\boldsymbol \\theta(.)$\n\nWe can find these parameters with a proper well defined training set $\\mathcal{D}$ (MLE, MAP, EM, full bayesian) or with partial data (for example we do not have labels for some features).\n\n##### MLE: Maximum Likelihood Estimate\nMLE gives a point estimate. We maximize the likelihood of the data given our model:\n\n$$\n\\hat{\\boldsymbol \\theta}_{MLE} = \\underset{\\boldsymbol \\theta}{argmax} ~ L(\\boldsymbol \\theta)\n= \\underset{\\boldsymbol \\theta}{argmax} ~ p(\\mathcal{D} | \\boldsymbol \\theta)\n$$\n\n##### MAP: Maximum a Posteriori\nMAP gives a point estimate. We maximize the likelihood of the label given the training data and defined priors:\n$$\n\\hat{\\boldsymbol \\theta}_{MAP} \n= \\underset{\\boldsymbol \\theta}{argmax} ~ p(\\boldsymbol \\theta | \\mathcal{D})\n= \\underset{\\boldsymbol \\theta}{argmax} ~ p(\\mathcal{D} | \\boldsymbol \\theta) p(\\boldsymbol \\theta)\n$$\n\n##### Bayesian estimation\nInstead of maximising the posterior distribution, we can integrate over the parameters in order to find the value of the distribution for a given variable value.\n\n\n##### Expectation maximization\n"},{"fields":{"slug":"/ML/Positive Definite Matrix/","title":"Positive Definite Matrix"},"frontmatter":{"draft":false},"rawBody":"- `semidefinite` matrix garantes: $\\forall \\boldsymbol{x}, \\boldsymbol{x}^T\\boldsymbol{A}\\boldsymbol{x} \\ge 0$\n- `definite` matrix garantes: $\\forall \\boldsymbol{x}, \\boldsymbol{x}^T\\boldsymbol{A}\\boldsymbol{x} \\ge 0$ and $\\boldsymbol{x}^T\\boldsymbol{A}\\boldsymbol{x} = 0 \\Rightarrow  \\boldsymbol{x} = 0$"},{"fields":{"slug":"/ML/RANSAC/","title":"Overview"},"frontmatter":{"draft":false},"rawBody":"**Random Sample Consensus** is an iterative method to estimate parameters of a mathematical model from a set of observed data that contains **outliers**, when outliers are to be accorded to influence on the values of the estimates. Therefore, it also can be interpreted as an outlier detection method.\n\nIt is a non-deterministic algorithm.\n\n# Overview\nThe RANSAC algorithm is a learning technique to estimate parameters of a model by random sampling of observed data. Given a dataset whose data elements contain both inliers and outliers, RANSAC uses the voting scheme to find the optimal fitting result. Data elements in the dataset are used to vote for one or multiple models. The implementation of this voting scheme is based on two assumptions: that the noisy features will not vote consistently for any single model (few outliers) and there are enough features to agree on a good model (few missing data). The RANSAC algorithm is essentially composed of two steps that are iteratively repeated:\n\n1.  In the first step, a sample subset containing minimal data items is randomly selected from the input dataset. A fitting model and the corresponding model parameters are computed using only the elements of this sample subset. The cardinality of the sample subset is the smallest sufficient to determine the model parameters.\n2.  In the second step, the algorithm checks which elements of the entire dataset are consistent with the model instantiated by the estimated model parameters obtained from the first step. A data element will be considered as an outlier if it does not fit the fitting model instantiated by the set of estimated model parameters within some error threshold that defines the maximum deviation attributable to the effect of noise.\n\nThe set of inliers obtained for the fitting model is called the consensus set. The RANSAC algorithm will iteratively repeat the above two steps until the obtained consensus set in certain iteration has enough inliers.\n\nThe input to the RANSAC algorithm is a set of observed data values, a way of fitting some kind of model to the observations, and some [confidence](https://en.wikipedia.org/wiki/Confidence_interval \"Confidence interval\") parameters. RANSAC achieves its goal by repeating the following steps:\n\n1.  Select a random subset of the original data. Call this subset the _hypothetical inliers_.\n2.  A model is fitted to the set of hypothetical inliers.\n3.  All other data are then tested against the fitted model. Those points that fit the estimated model well, according to some model-specific [loss function](https://en.wikipedia.org/wiki/Loss_function \"Loss function\"), are considered as part of the _consensus set_.\n4.  The estimated model is reasonably good if sufficiently many points have been classified as part of the consensus set.\n5.  Afterwards, the model may be improved by reestimating it using all members of the consensus set.\n\nThis procedure is repeated a fixed number of times, each time producing either a model which is rejected because too few points are part of the consensus set, or a refined model together with a corresponding consensus set size. In the latter case, we keep the refined model if its consensus set is larger than the previously saved model.\n\n![[Pasted image 20211231124420.png]]"},{"fields":{"slug":"/ML/Regression losses/","title":"Regression Losses"},"frontmatter":{"draft":false},"rawBody":"| Name           | Equation          | Comments                                      |\n|----------------|-------------------|-----------------------------------------------|\n| MSE            | $\\frac{1}{m} \\sum_i \\left(\\hat{\\boldsymbol{y}}-\\boldsymbol{y}\\right)_{i}^{2}$ |                                      |\n| Name           | Equation          |                                       |\n| Name           | Equation          |                                       |"},{"fields":{"slug":"/ML/Singular Value Decomposition (SVD)/","title":"Singular Value Decomposition (SVD)"},"frontmatter":{"draft":false},"rawBody":"Similar to [[Eigendecomposition]] but decomposes a matrix into `singular vectors` and `singular values`. SVD is more general than Eigendecomposition because all real matrix have an SVD.\n\nSVD decomposes $\\boldsymbol{A}$ as:\n$$ \n\\begin{align}\n&\\boldsymbol{A} =  \\boldsymbol{U}\\boldsymbol{D}\\boldsymbol{V}^{T} \\\\\n&\\text{ where } \n\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}, \n\\boldsymbol{U} \\in \\mathbb{R}^{m \\times m}, \n\\boldsymbol{D} \\in \\mathbb{R}^{m \\times n}, \n\\boldsymbol{V} \\in \\mathbb{R}^{n \\times n}\n\\end{align}\n$$\n$\\boldsymbol{U}$ and $\\boldsymbol{V}$ are both `orthogonal` matrices. $\\boldsymbol{D}$ is defined to be a diagonal matrix, but is not necessarily square.\n\nWe can use SVD to generalise matrix inversion to non-sqaure matrices, see [[Moore-Penrose Pseudoinverse]].\n"},{"fields":{"slug":"/ML/Symmetric matrix/","title":"Symmetric Matrix"},"frontmatter":{"draft":false},"rawBody":"$\\boldsymbol{A} = \\boldsymbol{A}^T$"},{"fields":{"slug":"/ML/Trace of matrix/","title":"Trace of Matrix"},"frontmatter":{"draft":false},"rawBody":"- $Tr(\\boldsymbol{A}) = \\sum_i \\boldsymbol{A}_{i,i}$  \n- $Tr(\\boldsymbol{A}) = Tr(\\boldsymbol{A}^T)$    \n- $Tr(\\boldsymbol{A}\\boldsymbol{B}\\boldsymbol{C}) = Tr(\\boldsymbol{C}\\boldsymbol{A}\\boldsymbol{B}) = Tr(\\boldsymbol{B}\\boldsymbol{C}\\boldsymbol{A})$\n- "},{"fields":{"slug":"/ML/Variance and Standard error/","title":"Variance and Standard Error"},"frontmatter":{"draft":false},"rawBody":"\n|Name | Formula  | Comment  |\n|----------------------------------|----------------------------------|-------------------------------|\n|Variance of population            |$\\frac{1}{n} \\sum (x_i - \\mu)^2$  |   \t\t\t\t\t\t       |\n|Variance of **sample**     \t   |$\\frac{1}{n-1}\\sum(x_i-\\mu)^2$    | **<-  notice the N - 1 !!!**  |\n|Standard error of the mean \t   |$\\frac{\\sigma}{\\sqrt(n)}$         |                               |\n|Confidence interval for a var \t   |$P(L<X<U)$ gives $L=\\mu-z\\sigma, U=\\mu+z\\sigma$ | [see standard score](https://en.wikipedia.org/wiki/Standard_score) |\n|Confidence interval for a Mean !! |$P(L<X<U)$ gives $L=\\mu-z\\frac{\\sigma}{\\sqrt(n)}, U=\\mu+z\\frac{\\sigma}{\\sqrt(n)}$ | [see standard score](https://en.wikipedia.org/wiki/Standard_score) |\n"},{"fields":{"slug":"/ML/trust region/","title":"Trust Region"},"frontmatter":{"draft":false},"rawBody":"[Trust Region](https://en.wikipedia.org/wiki/Trust_region)"},{"fields":{"slug":"/Papers/VICREG  variance-invariance-covariance regulaization for self-supervised Learning/","title":"Questions"},"frontmatter":{"draft":false},"rawBody":"# Questions\n### Do we need both network for inference / Which network do we chose ? \n### What is collapse ? Are there different way of collapsing ? \n- All embedding vectors collapse to a trivbial constant solution \n- Dimentional collapse: the embedding vectors end up spanning a lower-dimensional subspace instead of the entire available embedding space. See [UNDERSTANDINGDIMENSIONALCOLLAPSE INCON-TRASTIVESELF-SUPERVISEDLEARNING](https://arxiv.org/pdf/2110.09348.pdf)\n- \n### Why do we need both Covariance and Variance loss terms ? \n### What is the benefit of having different archictectures and different weights ? \n\n### Why decorelating at embeddings lvl also decorrelate at representation lvl ? \n\n# Minor questions\n### What is LARS optimizer ? \n\n"},{"fields":{"slug":"/Programming/Peak and Valleys/","title":"Example problem: Min Rewards (hard pb)"},"frontmatter":{"draft":false},"rawBody":"AKA min and max\n# Example problem: Min Rewards (hard pb)\nImagine that you're a teacher who's just graded the final exam in a class. You have a list of student scores on the final exam in a particular order (not necessarily sorted), and you want to reward your students. You decide to do so fairly by giving them arbitrary rewards following two rules:\n1. All students must receive at least one reward.\n2. Any given student must receive strictly more rewards than an adjacent student (a student immediately to the left or to the right) with a lower score and must receive strictly fewer rewards than an adjacent student with a higher score.\n\nWrite a function that takes in a list of scores and returns the minimum number of rewards that you must give out to students to satisfy the two rules.\nYou can assume that all students have different scores; in other words, the scores are all unique.\n\n### Samples input: \n```python\nscores = [8, 4, 2, 1, 3, 6, 7, 9, 5]\n```\n\n### Sample output:\n```python\n25 // you would give out the following rewards: [4, 3, 2, 1, 2, 3, 4, 5, 1]\n```\n\n# Solution Peak and Valley\n## Version 1\nIdentify the minimums in the list of scores. Each values that are local minimum (smaller than the value to the left or right) are going to be assigned a `1`. \nThen we want to go to the left and right of these local minimums, incrementing the rewards for each values.\n\n```\n### to lazy\n```\n\n## Version 2 (optimal)\nOnce we understood the previous solution, we can realise that we do not need to start from the local minimums. We can iterate from left to right, incrementing a value if the current value is greater than the previous. Then iterating in reverse order, and taking the max of current rewards or next rewards + 1 if the current value is greater than the next one.\n\n```python\n# O(n) time | O(n) space \ndef minRewards(scores):\n    rewards = [1] * len(scores)\n    for i in range(1, len(scores)):\n\t\tif scores[i] > scores[i - 1]:\n\t\t\trewards[i] = rewards[i - 1] + 1\n\tfor i in reversed(range(len(scores) - 1)):\n\t\tif scores[i] > scores[i + 1]:\n\t\t\trewards[i] = max(rewards[i], rewards[i + 1] + 1)\n\treturn sum(rewards)\n```\n"},{"fields":{"slug":"/Python/Dictionary/","title":"Dictionary"},"frontmatter":{"draft":false},"rawBody":"See Blob post about CPython implementation of Dict: https://www.laurentluce.com/posts/python-dictionary-implementation/  \nAnd original docstring comment in CPython code: https://github.com/python/cpython/blob/main/Objects/dictobject.c\n\n```python\nclass Dict:\n\n\tdef __init__(self, size=100):\n\t\tself.storage = [list() for _ in range(size)]\n\t\tself.size = size\n\t\tself.length = 0\n\t\n\tdef __setitem__(self, key, value):\n\t\tkey_pos = self._get_pos(key)\n\t\tfor pairs in self.storage[key_pos]:\n\t\t\tif key == pairs[0]:\n\t\t\t\t# update existing key with new value\n\t\t\t\tpairs[1] = value\n\t\t\t\tbreak\n\t\telse:\n\t\t\tself.storage[key_pos].append([key, value])\n\t\t\tself.length += 1\n\n\tdef __getitem__(self, key):\n\t\tkey_pos = self._get_pos(key)\n\t\t\tfor pairs in self.storage[key_pos]:\n\t\t\t\tif key == pairs[0]:\n\t\t\t\t\treturn pairs[1]\n\t\traise KeyError(f'Key {key} does not exists.')\n\t\n\t  \n\t\n\tdef __delitem__(self, key):\n\t\tkey_pos = self._get_pos(key)\n\t\tidx_to_remove = None\n\t\tfor idx, pairs in enumerate(self.storage[key_pos]):\n\t\t\tif key == pairs[0]:\n\t\t\t\tidx_to_remove = idx\n\t\t\t\tbreak\n\t\telse:\n\t\t\traise KeyError()\n\n\t\tdel self.storage[key_pos][idx_to_remove]\t\t\n\t\tself.length -=1\n\t\n\t  \n\t\n\tdef __len__(self):\n\t\treturn self.length\n\t\n\tdef __contains__(self, key):\n\t\tkey_pos = self._get_pos(key)\n\t\tfor pairs in self.storage[key_pos]:\n\t\t\tif key == pairs:\n\t\t\t\treturn True\n\t\treturn False\n\t\t\n\tdef __iter__(self):\n\t\tfor k, v in self.items():\n\t\t\tyield k\n\t\n\tdef keys(self):\n\t\treturn self.__iter__()\n\t\n\tdef values(self):\n\t\tfor k, v in self.items():\n\t\t\tyield v\n\t\n\tdef items(self):\n\t\tfor pairs in self.storage:\n\t\t\tfor pair in pairs:\n\t\t\t\tyield pair\n\n\tdef get(self, key, default=None):\n\t\ttry:\n\t\t\treturn self[key]\n\t\texcept KeyError:\n\t\t\treturn default\n\t\n\tdef _get_pos(self, key):\n\t\treturn hash(key) % self.size\n```"},{"fields":{"slug":"/Python/Is Python Compiled or Interpreted language/","title":"Is Python Compiled or Interpreted Language"},"frontmatter":{"draft":false},"rawBody":"Great answer here: https://discuss.python.org/t/is-python-a-compiled-language-or-an-interpreted-language/6556\n"},{"fields":{"slug":"/Python/pkg manager/Conda/","title":"Main Commands"},"frontmatter":{"draft":false},"rawBody":"# Main Commands\n\n| Description               \t| Command                             \t\t|\n|-----------------------------\t|----------------------------------------\t|\n| Create env from a yml file  \t| `conda env create -f environment.yml`  \t\t|\n| Create env from scratch     \t| `conda create --name SAIL python=3.7`  \t\t|\n| Remove env                  \t| `conda env remove --name SAIL`           \t\t|\n| Conda set number of threads \t| `conda config --set default_threads 6` \t\t|\n| Conda update env from file    | `conda env update --file environment.yml --prune `|\n| Conda export env without build specific info | `conda env export --no-builds` |\n\n\n# Complex commands\n\n#### Generate an environment file without all the packages, and without the pip section and the prefix section\n```shell  \nconda activate SAIL;conda env export --from-history > environments/tmp-words;\nconda env export --no-builds | sed '/- pip:/,$d' > environments/tmp-generated-base;\necho \"# GENERATED FILE, please see environments/README.md\" > environments/generated-base.yml;\ngrep -Fw -f environments/tmp-words environments/tmp-generated-base >> environments/generated-base.yml;\nrm environments/tmp-words environments/tmp-generated-base;\n```"},{"fields":{"slug":"/Python/pkg manager/Mamba/","title":"Mamba"},"frontmatter":{"draft":false},"rawBody":"[Documentation](https://mamba.readthedocs.io/en/latest/advanced_usage/package_resolution.html)"},{"fields":{"slug":"/Python/pkg manager/PIP/","title":"PIP"},"frontmatter":{"draft":false},"rawBody":"Install a package by from the default pip repository. This is usefull to bypass local pip forwarding to a secure Azure Pip repo when you do not have authentication tools downloaded yet.\n```shell\npip install artifacts-keyring --index-url https://pypi.org/simple\n```\n"},{"fields":{"slug":"/placeholder/","title":"This Is a Placeholder File for Mdx"},"frontmatter":{"draft":true},"rawBody":"---\ntitle: This Is a Placeholder File for Mdx\ndraft: true\ntags:\n  - gatsby-theme-primer-wiki-placeholder\n---\n"}]}}}