{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/ML/RANSAC/",
    "result": {"data":{"mdx":{"id":"bd850135-53dd-54bd-9ccb-d8a61ae1bacd","tableOfContents":{"items":[{"url":"#overview","title":"Overview"}]},"fields":{"title":"Overview","slug":"/ML/RANSAC/","url":"https://thomassajot.github.io/brain-dam/brain-dam/ML/RANSAC/","editUrl":"https://github.com/thomassajot/brain-dam/tree/main/ML/RANSAC.md","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022","gitCreatedAt":"2022-02-03T13:24:53.000Z","shouldShowTitle":false},"frontmatter":{"title":"","description":null,"imageAlt":null,"tags":[],"date":null,"dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Random Sample Consensus\"), \" is an iterative method to estimate parameters of a mathematical model from a set of observed data that contains \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"outliers\"), \", when outliers are to be accorded to influence on the values of the estimates. Therefore, it also can be interpreted as an outlier detection method.\"), mdx(\"p\", null, \"It is a non-deterministic algorithm.\"), mdx(\"h1\", {\n    \"id\": \"overview\"\n  }, \"Overview\"), mdx(\"p\", null, \"The RANSAC algorithm is a learning technique to estimate parameters of a model by random sampling of observed data. Given a dataset whose data elements contain both inliers and outliers, RANSAC uses the voting scheme to find the optimal fitting result. Data elements in the dataset are used to vote for one or multiple models. The implementation of this voting scheme is based on two assumptions: that the noisy features will not vote consistently for any single model (few outliers) and there are enough features to agree on a good model (few missing data). The RANSAC algorithm is essentially composed of two steps that are iteratively repeated:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"In the first step, a sample subset containing minimal data items is randomly selected from the input dataset. A fitting model and the corresponding model parameters are computed using only the elements of this sample subset. The cardinality of the sample subset is the smallest sufficient to determine the model parameters.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"In the second step, the algorithm checks which elements of the entire dataset are consistent with the model instantiated by the estimated model parameters obtained from the first step. A data element will be considered as an outlier if it does not fit the fitting model instantiated by the set of estimated model parameters within some error threshold that defines the maximum deviation attributable to the effect of noise.\")), mdx(\"p\", null, \"The set of inliers obtained for the fitting model is called the consensus set. The RANSAC algorithm will iteratively repeat the above two steps until the obtained consensus set in certain iteration has enough inliers.\"), mdx(\"p\", null, \"The input to the RANSAC algorithm is a set of observed data values, a way of fitting some kind of model to the observations, and some \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Confidence_interval\",\n    \"title\": \"Confidence interval\"\n  }, \"confidence\"), \" parameters. RANSAC achieves its goal by repeating the following steps:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Select a random subset of the original data. Call this subset the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"hypothetical inliers\"), \".\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"A model is fitted to the set of hypothetical inliers.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"All other data are then tested against the fitted model. Those points that fit the estimated model well, according to some model-specific \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://en.wikipedia.org/wiki/Loss_function\",\n    \"title\": \"Loss function\"\n  }, \"loss function\"), \", are considered as part of the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"consensus set\"), \".\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The estimated model is reasonably good if sufficiently many points have been classified as part of the consensus set.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Afterwards, the model may be improved by reestimating it using all members of the consensus set.\")), mdx(\"p\", null, \"This procedure is repeated a fixed number of times, each time producing either a model which is rejected because too few points are part of the consensus set, or a refined model together with a corresponding consensus set size. In the latter case, we keep the refined model if its consensus set is larger than the previously saved model.\"), mdx(\"p\", null, \"\", mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/brain-dam/static/0286298c7629ef4dd68ddf0c7b44cc4a/a805e/Pasted%20image%2020211231124420.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"46.42857142857143%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABIklEQVQoz22S627DIAyFef8n3L+p07Z0ISE3bjbgM5E0UdLWEgJj+HyMUXhYzgUpZ4hsfqt7LNbBOr/6IrKO3c7rs6mSMzjUiwGLJyzTBDcNsIHw9d3Ae38B1LkmOic54CJQJfG64JQROWMyPYb2DksFY9ei+71h0s0ar6NWUlVXxrPi6ipmgvfuyFQEyAIQJ3i3wPqA9vMD+ucGGxiLj/CRESmtCeq5XJ9qw0IRM7TWIKJD9tmqW0rBbFqYYQJxhguE2QVYT2j+OphxPlSq6+UNxpHAMUJKucB1Z3BvO4QYV2UpZXRmWKs4gOeH3YFunmHH8QBu+4+Y8+jNgL2OUuTSMPXcdnkpWV6+Te2y7g1SSi8xde2SvP0O7/YrlE/AXeE/wcfDwTlRrWsAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Pasted image 20211231124420\",\n    \"title\": \"Pasted image 20211231124420.png\",\n    \"src\": \"/brain-dam/static/0286298c7629ef4dd68ddf0c7b44cc4a/410f3/Pasted%20image%2020211231124420.png\",\n    \"srcSet\": [\"/brain-dam/static/0286298c7629ef4dd68ddf0c7b44cc4a/0d3e1/Pasted%20image%2020211231124420.png 140w\", \"/brain-dam/static/0286298c7629ef4dd68ddf0c7b44cc4a/6b1e2/Pasted%20image%2020211231124420.png 281w\", \"/brain-dam/static/0286298c7629ef4dd68ddf0c7b44cc4a/410f3/Pasted%20image%2020211231124420.png 561w\", \"/brain-dam/static/0286298c7629ef4dd68ddf0c7b44cc4a/a805e/Pasted%20image%2020211231124420.png 572w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Pasted image 20211231124420.png\"), \"\\n  \"), \"\"));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"**Random Sample Consensus** is an iterative method to estimate parameters of a mathematical model from a set of observed data that contains **outliers**, when outliers are to be accorded to influence on the values of the estimates. Therefore, it also can be interpreted as an outlier detection method.\n\nIt is a non-deterministic algorithm.\n\n# Overview\nThe RANSAC algorithm is a learning technique to estimate parameters of a model by random sampling of observed data. Given a dataset whose data elements contain both inliers and outliers, RANSAC uses the voting scheme to find the optimal fitting result. Data elements in the dataset are used to vote for one or multiple models. The implementation of this voting scheme is based on two assumptions: that the noisy features will not vote consistently for any single model (few outliers) and there are enough features to agree on a good model (few missing data). The RANSAC algorithm is essentially composed of two steps that are iteratively repeated:\n\n1.  In the first step, a sample subset containing minimal data items is randomly selected from the input dataset. A fitting model and the corresponding model parameters are computed using only the elements of this sample subset. The cardinality of the sample subset is the smallest sufficient to determine the model parameters.\n2.  In the second step, the algorithm checks which elements of the entire dataset are consistent with the model instantiated by the estimated model parameters obtained from the first step. A data element will be considered as an outlier if it does not fit the fitting model instantiated by the set of estimated model parameters within some error threshold that defines the maximum deviation attributable to the effect of noise.\n\nThe set of inliers obtained for the fitting model is called the consensus set. The RANSAC algorithm will iteratively repeat the above two steps until the obtained consensus set in certain iteration has enough inliers.\n\nThe input to the RANSAC algorithm is a set of observed data values, a way of fitting some kind of model to the observations, and some [confidence](https://en.wikipedia.org/wiki/Confidence_interval \"Confidence interval\") parameters. RANSAC achieves its goal by repeating the following steps:\n\n1.  Select a random subset of the original data. Call this subset the _hypothetical inliers_.\n2.  A model is fitted to the set of hypothetical inliers.\n3.  All other data are then tested against the fitted model. Those points that fit the estimated model well, according to some model-specific [loss function](https://en.wikipedia.org/wiki/Loss_function \"Loss function\"), are considered as part of the _consensus set_.\n4.  The estimated model is reasonably good if sufficiently many points have been classified as part of the consensus set.\n5.  Afterwards, the model may be improved by reestimating it using all members of the consensus set.\n\nThis procedure is repeated a fixed number of times, each time producing either a model which is rejected because too few points are part of the consensus set, or a refined model together with a corresponding consensus set size. In the latter case, we keep the refined model if its consensus set is larger than the previously saved model.\n\n![[Pasted image 20211231124420.png]]","excerpt":"Random Sample Consensus  is an iterative method to estimate parameters of a mathematical model from a set of observed data that contains  oâ€¦","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/ML/RANSAC/","sidebarItems":[{"title":"Categories","items":[{"title":"Azure","url":"","items":[{"title":"Azure Pipeline","url":"/Azure/Azure pipeline/","items":[]},{"title":"Documentation","url":"/Azure/Azure-ml/","items":[]}]},{"title":"Brain Dam","url":"/","items":[]},{"title":"Engineering","url":"","items":[{"title":"ACID","url":"/Engineering/Relational Databases/","items":[]},{"title":"API Design","url":"/Engineering/API Design/","items":[]},{"title":"Blob Store","url":"/Engineering/Specialized Storage Paradigms/","items":[]},{"title":"Cache for read","url":"/Engineering/Caching/","items":[]},{"title":"Client-Server Model","url":"/Engineering/Client-Server Model/","items":[]},{"title":"Configuration","url":"/Engineering/Configuration/","items":[]},{"title":"Consistent Hashing","url":"/Engineering/Consistent hashing/","items":[]},{"title":"Distributed Hash Table","url":"/Engineering/Distributed Hash Table/","items":[]},{"title":"Encryption","url":"/Engineering/Security and HTTPS/","items":[]},{"title":"Etcd","url":"/Engineering/Etcd/","items":[]},{"title":"Feature Flags","url":"/Engineering/Feature Flags/","items":[]},{"title":"Forward Proxy","url":"/Engineering/Proxies/","items":[]},{"title":"How does the load balancer work ?","url":"/Engineering/Load Balancer/","items":[]},{"title":"How to implement Leader election for your service ?","url":"/Engineering/Leader Election/","items":[]},{"title":"Idempotent Operation","url":"/Engineering/Idempotent Operation/","items":[]},{"title":"Important points","url":"/Engineering/MapReduce/","items":[]},{"title":"Latency","url":"/Engineering/Latency and Throughput/","items":[]},{"title":"Logging","url":"/Engineering/Logging and Monitoring/","items":[]},{"title":"Other strategy","url":"/Engineering/Jump hashing/","items":[]},{"title":"Other strategy","url":"/Engineering/Rendez-vous Hashing/","items":[]},{"title":"Polling","url":"/Engineering/Polling and Streaming/","items":[]},{"title":"Prometheus","url":"/Engineering/Prometheus/","items":[]},{"title":"Redis","url":"/Engineering/Redis/","items":[]},{"title":"Replication","url":"/Engineering/Replication and Sharding/","items":[]},{"title":"SLA / SLO","url":"/Engineering/Availability/","items":[]},{"title":"Socket","url":"/Engineering/Socket/","items":[]},{"title":"Storage Concept","url":"/Engineering/Storage concept/","items":[]},{"title":"Tools","url":"/Engineering/Key-Value Stores/","items":[]},{"title":"Tools","url":"/Engineering/Peer-To-Peer Networks/","items":[]},{"title":"Tools","url":"/Engineering/Publish-Subscribe Pattern/","items":[]},{"title":"Tools","url":"/Engineering/Rate Limiting/","items":[]},{"title":"Zookeeper","url":"/Engineering/Zookeeper/","items":[]}]},{"title":"ML","url":"","items":[{"title":"Constrained Optimization","url":"/ML/Constrained optimization/","items":[]},{"title":"Coordinate Descent","url":"/ML/Coordinate descent/","items":[]},{"title":"Determinant","url":"/ML/Determinant/","items":[]},{"title":"Dirichlet Distribution","url":"/ML/Dirichlet distribution/","items":[]},{"title":"Eigendecomposition","url":"/ML/Eigendecomposition/","items":[]},{"title":"Exploitation vs exploration","url":"/ML/Multi-armed bandit (AB testing)/","items":[]},{"title":"Frequentist A/B testing","url":"/ML/Frequentist AB testing/","items":[]},{"title":"Gradient","url":"/ML/Gradient/","items":[]},{"title":"Gradient Descend","url":"/ML/Gradient Descend/","items":[]},{"title":"Graph Neural Network","url":"/ML/GNN/","items":[]},{"title":"Hessian","url":"/ML/Hessian/","items":[]},{"title":"Jacobian","url":"/ML/Jacobian/","items":[]},{"title":"Kernel Trick","url":"/ML/Kernel Trick/","items":[]},{"title":"KKT conditions","url":"/ML/KKT/","items":[]},{"title":"Line Search","url":"/ML/Line Search/","items":[]},{"title":"Links","url":"/ML/Latent Dirichlet Allocation/","items":[]},{"title":"Maths","url":"/ML/PCA/","items":[]},{"title":"Matrix Inverse","url":"/ML/Matrix inverse/","items":[]},{"title":"Moore-Penrose Pseudoinverse","url":"/ML/Moore-Penrose Pseudoinverse/","items":[]},{"title":"Naive Bayes Classifier","url":"/ML/Naive Bayes Classifier/","items":[]},{"title":"Newton's Method","url":"/ML/Newton's method/","items":[]},{"title":"Norms","url":"/ML/Norms/","items":[]},{"title":"Overview","url":"/ML/RANSAC/","items":[]},{"title":"Parameter Estimation","url":"/ML/Parameter estimation/","items":[]},{"title":"Positive Definite Matrix","url":"/ML/Positive Definite Matrix/","items":[]},{"title":"Regression Losses","url":"/ML/Regression losses/","items":[]},{"title":"Singular Value Decomposition (SVD)","url":"/ML/Singular Value Decomposition (SVD)/","items":[]},{"title":"Symmetric Matrix","url":"/ML/Symmetric matrix/","items":[]},{"title":"Tool","url":"/ML/Bayesian AB testing/","items":[]},{"title":"Trace of Matrix","url":"/ML/Trace of matrix/","items":[]},{"title":"Trust Region","url":"/ML/trust region/","items":[]},{"title":"Variance and Standard Error","url":"/ML/Variance and Standard error/","items":[]}]},{"title":"Papers","url":"","items":[{"title":"Questions","url":"/Papers/VICREG  variance-invariance-covariance regulaization for self-supervised Learning/","items":[]}]},{"title":"Programming","url":"","items":[{"title":"Example problem: Min Rewards (hard pb)","url":"/Programming/Peak and Valleys/","items":[]}]},{"title":"Python","url":"","items":[{"title":"Dictionary","url":"/Python/Dictionary/","items":[]},{"title":"Is Python Compiled or Interpreted Language","url":"/Python/Is Python Compiled or Interpreted language/","items":[]},{"title":"Pkg Manager","url":"","items":[{"title":"Main Commands","url":"/Python/pkg manager/Conda/","items":[]},{"title":"Mamba","url":"/Python/pkg manager/Mamba/","items":[]},{"title":"PIP","url":"/Python/pkg manager/PIP/","items":[]}]}]},{"title":"Start Here","url":"/Start here/","items":[]},{"title":"Week 1","url":"/Coursera - Learning How to Learn/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/Engineering/Consistent hashing/","title":"Consistent Hashing","lastUpdatedAt":"2022-05-27T08:32:09.000Z","lastUpdated":"5/27/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/","title":"Brain Dam","lastUpdatedAt":"2022-05-26T21:19:43.000Z","lastUpdated":"5/26/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Engineering/Distributed Hash Table/","title":"Distributed Hash Table","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Engineering/Feature Flags/","title":"Feature Flags","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Engineering/Prometheus/","title":"Prometheus","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/ML/Gradient Descend/","title":"Gradient Descend","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Coursera - Learning How to Learn/","title":"Week 1","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Azure/Azure pipeline/","title":"Azure Pipeline","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Azure/Azure-ml/","title":"Documentation","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Engineering/API Design/","title":"API Design","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}