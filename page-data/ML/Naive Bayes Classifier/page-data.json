{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/ML/Naive Bayes Classifier/",
    "result": {"data":{"mdx":{"id":"bc24410b-c8aa-5dea-8a52-02b956c9a2e5","tableOfContents":{},"fields":{"title":"Naive Bayes Classifier","slug":"/ML/Naive Bayes Classifier/","url":"https://demo-obsidian.owenyoung.com/ML/Naive Bayes Classifier/","editUrl":"https://github.com/theowenyoung/obsidian-template-gatsby-theme-primer-wiki/tree/main/ML/Naive Bayes Classifier.md","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022","gitCreatedAt":"2022-02-03T13:24:53.000Z","shouldShowTitle":true},"frontmatter":{"title":"","description":null,"imageAlt":null,"tags":[],"date":null,"dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Given a corpus of text and their label as training set, we want to build a classifier that can give us a class given a text.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"More formally, given a vector of multiple discrete values features $\\\\boldsymbol x \\\\in \", \"{\", \"1, ...K\", \"}\", \"^D$ and a target label $y$. \"), mdx(\"p\", null, \"$$\"), mdx(\"p\", null, \"\\\\begin{aligned}\"), mdx(\"p\", null, \"p(y=c | \\\\boldsymbol x) & =  \\\\frac{p(y=c)p(\\\\boldsymbol x|y=c)}{p(\\\\boldsymbol x)} \", \"\\\\\", \"\\n& = \\\\frac{p(y=c)\\\\prod_{i=1}^D p(x_i|y=c)}{p(\\\\boldsymbol x)} \\\\Leftarrow \\\\textit{ naive assumption of conditional independence}\\n\\\\end{aligned}\\n$$\"), mdx(\"p\", null, \"For example, $\\\\boldsymbol x$ is a vector representing a document.\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"If $x_i$ represents the absence or presence of $word_i$ in a text. In this case, $K = 2$ because $x_i \\\\in \", \"{\", \"0, 1\", \"}\", \"$\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"If $x_i$ represents the frequency (count) of $word_i$ in a text, then $x_i$ can have any discrete value from 0 to infinity. So $x_i \\\\sim Cat(\\\\mu_i)$. A categorical distribution of the frequency to be 0, 1, 2, 125, ... So $\\\\mu_i$ is a vector of size $N$ which denotes the maximum frequency we have from the training set.\", mdx(\"br\", {\n    parentName: \"li\"\n  }), \"If in the text test we have a greater frequency, the probability of having this frequency is 0 ???\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"It is possible to handle other type of distribution for $x_i$ even different distributions for every features.\")), mdx(\"h3\", null, \"Directed Graphical Model\"), mdx(\"p\", null, \"![\", \"[Pasted image 20211215205658.png|200]\", \"] ^8d39ff\"), mdx(\"p\", null, \"Where:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"$\\\\boldsymbol \\\\pi$ is the prior of the categorical distribution of $Y$: $Y \\\\sim Cat(\\\\pi)$\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"$x_{ij}$ is the feature of the jth word for the ith document. $j \\\\in \", \"{\", \"1, ..., D\", \"}\", \"$ words (ie D is the vocab size) and $i \\\\in \", \"{\", \"1, ... N\", \"}\", \"$ documents. \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"$\\\\theta\", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"{jc}$ is the parameter of the $x\"), \"{ij}$ feature variable. The document $i$  is associated with a label $y_i$ which has values in the possible class $C$. \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The plates: there are $N$ documents, $D$ words across all N documents (vocab), there are $C$ possible outcome class values for $Y$. \")));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"Given a corpus of text and their label as training set, we want to build a classifier that can give us a class given a text.  \nMore formally, given a vector of multiple discrete values features $\\boldsymbol x \\in \\{1, ...K\\}^D$ and a target label $y$. \n\n$$\n\n\\begin{aligned}\n\np(y=c | \\boldsymbol x) & =  \\frac{p(y=c)p(\\boldsymbol x|y=c)}{p(\\boldsymbol x)} \\\\\n& = \\frac{p(y=c)\\prod_{i=1}^D p(x_i|y=c)}{p(\\boldsymbol x)} \\Leftarrow \\textit{ naive assumption of conditional independence}\n\\end{aligned}\n$$\n\nFor example, $\\boldsymbol x$ is a vector representing a document.\n1. If $x_i$ represents the absence or presence of $word_i$ in a text. In this case, $K = 2$ because $x_i \\in \\{0, 1\\}$\n2. If $x_i$ represents the frequency (count) of $word_i$ in a text, then $x_i$ can have any discrete value from 0 to infinity. So $x_i \\sim Cat(\\mu_i)$. A categorical distribution of the frequency to be 0, 1, 2, 125, ... So $\\mu_i$ is a vector of size $N$ which denotes the maximum frequency we have from the training set.   \n    If in the text test we have a greater frequency, the probability of having this frequency is 0 ???\n3. It is possible to handle other type of distribution for $x_i$ even different distributions for every features.\n\n### Directed Graphical Model\n![[Pasted image 20211215205658.png|200]] ^8d39ff\n\nWhere:\n- $\\boldsymbol \\pi$ is the prior of the categorical distribution of $Y$: $Y \\sim Cat(\\pi)$\n- $x_{ij}$ is the feature of the jth word for the ith document. $j \\in \\{1, ..., D\\}$ words (ie D is the vocab size) and $i \\in \\{1, ... N\\}$ documents. \n- $\\theta_{jc}$ is the parameter of the $x_{ij}$ feature variable. The document $i$  is associated with a label $y_i$ which has values in the possible class $C$. \n- The plates: there are $N$ documents, $D$ words across all N documents (vocab), there are $C$ possible outcome class values for $Y$. \n\n\n","excerpt":"Given a corpus of text and their label as training set, we want to build a classifier that can give us a class given a text. More formally,â€¦","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/ML/Naive Bayes Classifier/","sidebarItems":[{"title":"Categories","items":[{"title":"Azure","url":"","items":[{"title":"Azure Pipeline","url":"/Azure/Azure pipeline/","items":[]},{"title":"Documentation","url":"/Azure/Azure-ml/","items":[]}]},{"title":"Brain Dam: Keeping information Upd","url":"/","items":[]},{"title":"Engineering","url":"","items":[{"title":"ACID","url":"/Engineering/Relational Databases/","items":[]},{"title":"API Design","url":"/Engineering/API Design/","items":[]},{"title":"Blob Store","url":"/Engineering/Specialized Storage Paradigms/","items":[]},{"title":"Cache for read","url":"/Engineering/Caching/","items":[]},{"title":"Client-Server Model","url":"/Engineering/Client-Server Model/","items":[]},{"title":"Configuration","url":"/Engineering/Configuration/","items":[]},{"title":"Consistent hashing with bounded load","url":"/Engineering/Consistent hashing/","items":[]},{"title":"Distributed Hash Table","url":"/Engineering/Distributed Hash Table/","items":[]},{"title":"Encryption","url":"/Engineering/Security and HTTPS/","items":[]},{"title":"Etcd","url":"/Engineering/Etcd/","items":[]},{"title":"Feature Flags","url":"/Engineering/Feature Flags/","items":[]},{"title":"Forward Proxy","url":"/Engineering/Proxies/","items":[]},{"title":"How does the load balancer work ?","url":"/Engineering/Load Balancer/","items":[]},{"title":"How to implement Leader election for your service ?","url":"/Engineering/Leader Election/","items":[]},{"title":"Idempotent Operation","url":"/Engineering/Idempotent Operation/","items":[]},{"title":"Important points","url":"/Engineering/MapReduce/","items":[]},{"title":"Latency","url":"/Engineering/Latency and Throughput/","items":[]},{"title":"Logging","url":"/Engineering/Logging and Monitoring/","items":[]},{"title":"Other strategy","url":"/Engineering/Jump hashing/","items":[]},{"title":"Other strategy","url":"/Engineering/Rendez-vous Hashing/","items":[]},{"title":"Polling","url":"/Engineering/Polling and Streaming/","items":[]},{"title":"Prometheus","url":"/Engineering/Prometheus/","items":[]},{"title":"Redis","url":"/Engineering/Redis/","items":[]},{"title":"Replication","url":"/Engineering/Replication and Sharding/","items":[]},{"title":"SLA / SLO","url":"/Engineering/Availability/","items":[]},{"title":"Socket","url":"/Engineering/Socket/","items":[]},{"title":"Storage Concept","url":"/Engineering/Storage concept/","items":[]},{"title":"Tools","url":"/Engineering/Key-Value Stores/","items":[]},{"title":"Tools","url":"/Engineering/Peer-To-Peer Networks/","items":[]},{"title":"Tools","url":"/Engineering/Publish-Subscribe Pattern/","items":[]},{"title":"Tools","url":"/Engineering/Rate Limiting/","items":[]},{"title":"Zookeeper","url":"/Engineering/Zookeeper/","items":[]}]},{"title":"ML","url":"","items":[{"title":"Constrained Optimization","url":"/ML/Constrained optimization/","items":[]},{"title":"Coordinate Descent","url":"/ML/Coordinate descent/","items":[]},{"title":"Determinant","url":"/ML/Determinant/","items":[]},{"title":"Dirichlet Distribution","url":"/ML/Dirichlet distribution/","items":[]},{"title":"Eigendecomposition","url":"/ML/Eigendecomposition/","items":[]},{"title":"Exploitation vs exploration","url":"/ML/Multi-armed bandit (AB testing)/","items":[]},{"title":"Frequentist A/B testing","url":"/ML/Frequentist AB testing/","items":[]},{"title":"Gradient","url":"/ML/Gradient/","items":[]},{"title":"Gradient Descend","url":"/ML/Gradient Descend/","items":[]},{"title":"Graph Neural Network","url":"/ML/GNN/","items":[]},{"title":"Hessian","url":"/ML/Hessian/","items":[]},{"title":"Jacobian","url":"/ML/Jacobian/","items":[]},{"title":"Kernel Trick","url":"/ML/Kernel Trick/","items":[]},{"title":"KKT conditions","url":"/ML/KKT/","items":[]},{"title":"Line Search","url":"/ML/Line Search/","items":[]},{"title":"Links","url":"/ML/Latent Dirichlet Allocation/","items":[]},{"title":"Maths","url":"/ML/PCA/","items":[]},{"title":"Matrix Inverse","url":"/ML/Matrix inverse/","items":[]},{"title":"Moore-Penrose Pseudoinverse","url":"/ML/Moore-Penrose Pseudoinverse/","items":[]},{"title":"Naive Bayes Classifier","url":"/ML/Naive Bayes Classifier/","items":[]},{"title":"Newton's Method","url":"/ML/Newton's method/","items":[]},{"title":"Norms","url":"/ML/Norms/","items":[]},{"title":"Overview","url":"/ML/RANSAC/","items":[]},{"title":"Parameter Estimation","url":"/ML/Parameter estimation/","items":[]},{"title":"Positive Definite Matrix","url":"/ML/Positive Definite Matrix/","items":[]},{"title":"Regression Losses","url":"/ML/Regression losses/","items":[]},{"title":"Singular Value Decomposition (SVD)","url":"/ML/Singular Value Decomposition (SVD)/","items":[]},{"title":"Symmetric Matrix","url":"/ML/Symmetric matrix/","items":[]},{"title":"Tool","url":"/ML/Bayesian AB testing/","items":[]},{"title":"Trace of Matrix","url":"/ML/Trace of matrix/","items":[]},{"title":"Trust Region","url":"/ML/trust region/","items":[]},{"title":"Variance and Standard Error","url":"/ML/Variance and Standard error/","items":[]}]},{"title":"Papers","url":"","items":[{"title":"Questions","url":"/Papers/VICREG  variance-invariance-covariance regulaization for self-supervised Learning/","items":[]}]},{"title":"Programming","url":"","items":[{"title":"Example problem: Min Rewards (hard pb)","url":"/Programming/Peak and Valleys/","items":[]}]},{"title":"Python","url":"","items":[{"title":"Dictionary","url":"/Python/Dictionary/","items":[]},{"title":"Is Python Compiled or Interpreted Language","url":"/Python/Is Python Compiled or Interpreted language/","items":[]},{"title":"Pkg Manager","url":"","items":[{"title":"Main Commands","url":"/Python/pkg manager/Conda/","items":[]},{"title":"Mamba","url":"/Python/pkg manager/Mamba/","items":[]},{"title":"PIP","url":"/Python/pkg manager/PIP/","items":[]}]}]},{"title":"Start Here","url":"/Start here/","items":[]},{"title":"Week 1","url":"/Coursera - Learning How to Learn/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/Engineering/Distributed Hash Table/","title":"Distributed Hash Table","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Engineering/Feature Flags/","title":"Feature Flags","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Engineering/Prometheus/","title":"Prometheus","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/ML/Gradient Descend/","title":"Gradient Descend","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Coursera - Learning How to Learn/","title":"Week 1","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Azure/Azure pipeline/","title":"Azure Pipeline","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Azure/Azure-ml/","title":"Documentation","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Engineering/API Design/","title":"API Design","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Engineering/Availability/","title":"SLA / SLO","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Engineering/Caching/","title":"Cache for read","lastUpdatedAt":"2022-02-03T13:24:53.000Z","lastUpdated":"2/3/2022"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}